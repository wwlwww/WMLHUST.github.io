{"meta":{"title":"小本本","subtitle":"学而时习之，不亦说乎","description":"厉害了~","author":"WordGe","url":"http://yoursite.com","root":"/"},"pages":[{"title":"categories","date":"2020-05-11T09:14:14.000Z","updated":"2020-05-11T09:14:36.963Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2020-05-11T09:20:22.000Z","updated":"2020-05-11T09:22:25.642Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"about about"},{"title":"tags","date":"2020-05-11T09:10:36.000Z","updated":"2020-05-11T09:11:52.492Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"分布式事务常见方案","slug":"分布式事务","date":"2020-07-25T15:50:31.000Z","updated":"2020-07-25T15:50:31.000Z","comments":true,"path":"2020/07/25/分布式事务/","link":"","permalink":"http://yoursite.com/2020/07/25/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"分布式事务是个复杂繁琐的问题，如果能够通过调整业务或架构，避免分布式事务，尽量避免。 下面总结、对比一下常见的分布式事务实现方案： 1. 2PC / XAXA规范的协议原理即为 2PC。关键点： 需要一个事务协调器。 每个实例，分为两个阶段，第一阶段prepare，第二阶段，commit/rollback。 存在问题： 事务协调器，单点故障。故障时，为了保证事务连续，只能等待该协调器重启恢复。 性能问题，阶段1，锁定资源后，必须要等所有节点返回，然后才能一同进入阶段2。 如果commit部分成功，将出现数据不一致。此时只能不断重试，直到成功。 2. 3PC3PC的三个阶段分别是canCommit、preCommit、doCommit。相比两阶段提交： 多了preCommit一步，实际是把2PC划分得更细。2PC在阶段1时，如果部分成功，则rollback。而在阶段2时，如果部分成功（实际上，每个实例应该保证，一旦收到commit，必定能成功。前提条件检查应放在阶段1做。），则只能不断重试。3PC拆分得更细后，根据不同阶段的超时，执行不同的动作。当然，2PC中，实例也可以在阶段2，等待commit超时后rollback。不能是commit，因为可能阶段1不是全部成功，出于一致性考虑，只能rollback，然后调用方不断重试。3PC分为两个阶段后，超时更好控制。在阶段2等待preCommit超时和2PC中等待commit超时一样，需要rollback。但是如果在阶段3等待doCommit超时，至少能确定canCommit都是成功的，因此可以执行commit。 相比2PC，增加超时功能，减少对事务协调器的依赖，避免持续阻塞： 实例等待preCommit指令时，超时后自动 rollback 实例等待doCommit指令时，超时后自动 commit 然而，3PC也需要协调者，协调者也需要等待各个实例的回复，这些回复也可能超时。根源在于，通信信道没有保证，因此两个节点之间，如果超时，无法确定对方是宕机了，还是消息丢失了。所以，此时是成功了，还是失败了呢？ 3. TCCTCC (Try - Confirm - Cancel)相比TCC，更偏向应用层一点，比如服务间调用，各阶段之间会穿插一些业务逻辑等。2PC、3PC更像是协调两个数据库实例。比如：一个订单服务需要支付、库存、积分、物流多个服务的状态保持一致。一般使用一些TCC事务框架，框架需要保存事务日志之类的。 如果try失败，调用cancel 如果confirm失败，不停重试confirm 如果cancel失败，不停重试cancel 因此try/confirm/cancel接口需要幂等，因此需要一些事务ID之类的东西，TCC框架可以协助实现。 参考文章： 介绍TCC流程，https://juejin.im/post/5bf201f7f265da610f63528a 介绍TCC细节，https://yemablog.com/posts/tcc-1 4. 消息中间件（实现的是最终一致）这个没啥特别的，主要是利用消息队列解耦，从而A完成事务后可直接返回，B从MQ中取消息，发生错误则不断尝试。 特别提一下rocketMQ事务消息的实现原理：rocketMQ的消息发送，分为两个阶段：prepare和confirm。当confirm后，broker才会将消息传递给消费方。对于一直未confirm的消息，broker会定期扫描，询问发送方此消息，是发送还是取消。 再特别提一下，两个服务之间，最终一致性的关键：持久化中间件（MySQL，消息对列等），配合幂等重试。比如转账，A服务扣了钱，记录进DB。异步调用B服务加钱接口，失败则重试，直到成功。（失败多次后，一般会人工介入） 参考文章 https://xiaomi-info.github.io/2020/01/02/distributed-transaction/","categories":[{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"系统原理","slug":"后端/系统原理","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"python多元赋值的一个顺序问题","slug":"python多元赋值的一个顺序问题","date":"2020-07-12T10:50:22.000Z","updated":"2020-07-12T10:50:22.000Z","comments":true,"path":"2020/07/12/python多元赋值的一个顺序问题/","link":"","permalink":"http://yoursite.com/2020/07/12/python%E5%A4%9A%E5%85%83%E8%B5%8B%E5%80%BC%E7%9A%84%E4%B8%80%E4%B8%AA%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98/","excerpt":"","text":"起因是试验一个python翻转链表的代码，python的变量交换非常方便，比如交换两个元素，可以直接a, b = b, a，因此翻转链表，可以这么写： 1234567def reverseList(head: ListNode) : pre = None cur = head while cur is not None: cur, pre, cur.next = cur.next, cur, pre return pre 然而，这个代码是错误的。 \b经过单步debug，发现在第一次交换发生时，交换的结果就不对。不用怀疑，如果是 a, b, c = b, c, a，那肯定是对的。所以问题出在哪里？不会是python的一个bug吧？追根溯源，直接看下字节码： 123456789101112131415import dis# 初始化链表n0 = ListNode(0)n1 = ListNode(1)n2 = ListNode(2)n3 = ListNode(3)n0.next = n1n1.next = n2n2.next = n3# 查看交换代码的字节码pre = Nonecur = n0dis.dis(\"cur, pre, cur.next = cur.next, cur, pre\") 输出是 12345678910111213141516171819202122# 0-10步，先依次取右值 cur.next, cur, pre，然后倒序 0 LOAD_NAME 0 (cur) # 取cur值，push入栈 2 LOAD_ATTR 1 (next) # 取cur.next，替换栈顶 4 LOAD_NAME 0 (cur) # 取cur值，push入栈 6 LOAD_NAME 2 (pre) # 取pre值，push入栈 8 ROT_THREE10 ROT_TWO # ROT_3和ROT_2两步的效果，就是对栈内的3个元素倒序 # 目前栈内从顶至底分别为[old_cur_next, old_cur, old_pre]# 以上步骤没有问题，提前准备好要赋值的数据。# 接下来，依次赋值左边变量，cur, pre, cur.next12 STORE_NAME 0 (cur) # pop栈顶，赋值给 cur (new_cur = old_cur_next) # 此时栈 [old_cur, old_pre]14 STORE_NAME 2 (pre) # pop栈顶，赋值给 pre (new_pre = old_cur) # 此时栈 [old_pre]16 LOAD_NAME 0 (cur) # 取cur值，push入栈 # 此时栈 [new_cur, old_pre]18 STORE_ATTR 1 (next) # 将栈顶元素(也就是cur)的next属性，赋值为栈的第二个元素 # new_cur.next = old_pre 关键在于第16步，重新load了一下cur，而此时cur已经在第12步，被赋值为old_cur_next。实际执行的是new_cur.next = old_pre，而我们的目标是old_cur.next = old_pre。因此出现了不一致。 关键在于 多元赋值中，左边被赋值的变量是有先后关系的。先改变了cur，那么再给cur.next赋值时，cur就已经是新的cur。因此如果同时需要改变cur、cur.next的值，应该优先赋值cur.next。 修改后的代码： 12345678def reverseList(head: ListNode) : pre = None cur = head while cur is not None: # cur, pre, cur.next = cur.next, cur, pre cur.next, pre, cur = pre, cur, cur.next return pre","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"剑指offer题目思路简结-3","slug":"剑指offer题目思路简结-3","date":"2020-06-25T01:36:29.000Z","updated":"2020-06-25T01:36:29.000Z","comments":true,"path":"2020/06/25/剑指offer题目思路简结-3/","link":"","permalink":"http://yoursite.com/2020/06/25/%E5%89%91%E6%8C%87offer%E9%A2%98%E7%9B%AE%E6%80%9D%E8%B7%AF%E7%AE%80%E7%BB%93-3/","excerpt":"","text":"1. [剑指 Offer 50. 第一个只出现一次的字符](#剑指-offer-50-第一个只出现一次的字符) 2. [剑指 Offer 51. 数组中的逆序对](#剑指-offer-51-数组中的逆序对) 3. [剑指 Offer 52. 两个链表的第一个公共节点](#剑指-offer-52-两个链表的第一个公共节点) 4. [剑指 Offer 53 - I. 在排序数组中查找数字 I](#剑指-offer-53---i-在排序数组中查找数字-i) 5. [指 Offer 53 - II. 0～n-1中缺失的数字](#指-offer-53---ii-0n-1中缺失的数字) 6. [剑指 Offer 54. 二叉搜索树的第k大节点](#剑指-offer-54-二叉搜索树的第k大节点) 7. [剑指 Offer 55 - I. 二叉树的深度](#剑指-offer-55---i-二叉树的深度) 8. [剑指 Offer 55 - II. 平衡二叉树](#剑指-offer-55---ii-平衡二叉树) 9. [剑指 Offer 56 - I. 数组中数字出现的次数](#剑指-offer-56---i-数组中数字出现的次数) 10. [剑指 Offer 56 - II. 数组中数字出现的次数 II](#剑指-offer-56---ii-数组中数字出现的次数-ii) 11. [剑指 Offer 57 - II. 和为s的连续正数序列](#剑指-offer-57---ii-和为s的连续正数序列) 12. [剑指 Offer 58 - I. 翻转单词顺序](#剑指-offer-58---i-翻转单词顺序) 13. [剑指 Offer 58 - II. 左旋转字符串](#剑指-offer-58---ii-左旋转字符串) 14. [剑指 Offer 59 - I. 滑动窗口的最大值](#剑指-offer-59---i-滑动窗口的最大值) 15. [剑指 Offer 59 - II. 队列的最大值](#剑指-offer-59---ii-队列的最大值) 16. [剑指 Offer 60. n个骰子的点数](#剑指-offer-60-n个骰子的点数) 17. [剑指 Offer 61. 扑克牌中的顺子](#剑指-offer-61-扑克牌中的顺子) 18. [剑指 Offer 62. 圆圈中最后剩下的数字](#剑指-offer-62-圆圈中最后剩下的数字) 19. [剑指 Offer 63. 股票的最大利润](#剑指-offer-63-股票的最大利润) 20. [剑指 Offer 64. 求1+2+…+n](#剑指-offer-64-求12n) 21. [剑指 Offer 65. 不用加减乘除做加法](#剑指-offer-65-不用加减乘除做加法) 22. [剑指 Offer 66. 构建乘积数组](#剑指-offer-66-构建乘积数组) 23. [剑指 Offer 67. 把字符串转换成整数](#剑指-offer-67-把字符串转换成整数) 24. [剑指 Offer 68 - I. 二叉搜索树的最近公共祖先](#剑指-offer-68---i-二叉搜索树的最近公共祖先) 25. [剑指 Offer 68 - II. 二叉树的最近公共祖先](#剑指-offer-68---ii-二叉树的最近公共祖先) 完结散花 ~ 剑指 Offer 50. 第一个只出现一次的字符遍历字符串，搞个map记录字符出现次数。再次遍历字符串，遇到出现次数为 1 的就返回。 剑指 Offer 51. 数组中的逆序对这题值得hard难度。如果暴力解法，时间复杂度将是O(N^2)。比排序的O(NlogN)还大，那么可否先排序在比较，降低复杂度？比如 [7, 5, 6, 4] 先均分为两部分 [7, 5] 和 [6, 4]，分别排序得到，[5, 7] 和 [4, 6]。 对于5，发现只比4大，说明只有一个[5, 4]，对于7，继续与6比较，而不用继续跟4比较，说明有[7, 4]、[7, 6] 两个。 继续分别针对[7，5] 和 [6, 4] 重复 均分-&gt;排序-&gt;比较 这个过程。分别只有一个结果[7, 5]和[6, 4]。 所以最终结果为 5 123456789101112131415161718192021222324252627282930class Solution: def reversePairs(self, nums: List[int]) -&gt; int: # 比较两个排好序的子数组 def computePairs(arr1: List[int], arr2: List[int]) -&gt; int: if len(arr1) == 0 or len(arr2) == 0: return 0 l = 0 r = 0 res = 0 while l&lt;len(arr1) : while r &lt; len(arr2) and arr1[l] &gt; arr2[r]: r += 1 res += r l+=1 return res if len(nums) &lt;= 1: return 0 # 划分 &amp; 排序 nums2 = nums.copy() left_arr = nums[:len(nums2)//2] right_arr = nums[len(nums2)//2:] left_arr.sort() right_arr.sort() # 计算本身结果，并递归子数组 return computePairs(left_arr, right_arr) \\ + self.reversePairs(nums[:len(nums)//2]) \\ + self.reversePairs(nums[len(nums)//2:]) 剑指 Offer 52. 两个链表的第一个公共节点最简单的，先计算长度，然后比较两者的长度差，再利用快慢指针。一个巧妙的办法： 123456789101112class Solution: def getIntersectionNode(self, headA: ListNode, headB: ListNode) -&gt; ListNode: c1 = headA c2 = headB # 1. 最终c1和c2走的长度是相等的，LA + LB # 2. 如果不存在相交，c1走到B的结尾时会被赋值为None，此时c2也恰好走到A的结尾被赋值为None，刚好两者相等，跳出循环 while c1 != c2: c1 = c1.next if c1 else headB c2 = c2.next if c2 else headA return c1 剑指 Offer 53 - I. 在排序数组中查找数字 I先二分查找位置，再左右扩展。复杂度最差 O(N)，平均 O(logN) + O(M)。M为结果个数。如果M==N，则平均复杂度退化为 O(logN) + O(N)再优化一下，可以先查左边界，再查右边界。就是 O(logN) 的复杂度，避免了最差O(N)的复杂度。 都比暴力解法强吧 [doge][doge] 指 Offer 53 - II. 0～n-1中缺失的数字规律是：在缺失数左侧，每个数与其索引是相等的；在缺失数右侧，每个数 &gt; 其索引。因此可利用二分查找缺失数的位置。 剑指 Offer 54. 二叉搜索树的第k大节点按 右子树 -&gt; 根 -&gt; 左子树 的顺序遍历，使用全局变量记录还需遍历多少个节点。 1234567891011121314151617181920212223242526class Solution: def kthLargest(self, root: TreeNode, k: int) -&gt; int: # 返回 # 1. 是否找到 # 2. 对应的值 def dfs(r: TreeNode) -&gt; (bool, int): if r is None: return False, 0 # 遍历右子树 found, val = dfs(r.right) if found: return found, val # 遍历根 if self.nk == 1: return True, r.val self.nk -= 1 # 遍历左子树 return dfs(r.left) self.nk = k _, v = dfs(root) return v 剑指 Offer 55 - I. 二叉树的深度DFS，Depth(root) = 1 + max(Depth(root.left), Depth(root.right)) 剑指 Offer 55 - II. 平衡二叉树 解法一：计算并检查每一个节点左右子树的深度，但是这样做会有很多的重复计算。 解法二：自底向上，同时记录当前子树的深度，从而在计算父节点的深度时，避免重复计算。123456789101112131415161718192021# -1 表示非平衡，直接返回# &gt;=0 表示树的深度def valid(root: TreeNode) -&gt; (int): if root is None: return 0 left = valid(root.left) if left == -1: return -1 right = valid(root.right) if right == -1: return -1 if abs(left - right) &gt; 1: return -1 return max(left, right) + 1class Solution: def isBalanced(self, root: TreeNode) -&gt; bool: return valid(root) != -1 剑指 Offer 56 - I. 数组中数字出现的次数 如果一个数组中，只有一个数字出现了一次，其他数字都出现了两次，那么可以通过对所有数字进行xor操作，最后得到的就是该数 如果有两个数字a, b出现了一次，可以想办法将这两个数字划分到两个子数组，这两个子数组除下a, b外，其他都出现了两次，则可直接根据上述规律，xor遍历一遍得到a, b123456789101112131415161718192021class Solution: def singleNumbers(self, nums: List[int]) -&gt; List[int]: xor_res = 0 for v in nums: xor_res = xor_res ^ v # 找xor_res为1的那一位 # 也就是res1 和 res2 不同的那一位 div = 1 while (xor_res &amp; div) == 0: div = div &lt;&lt; 1 xor1 = 0 xor2 = 0 for v in nums: if v &amp; div == 0: xor1 = xor1 ^ v else: xor2 = xor2 ^ v return [xor1, xor2] 剑指 Offer 56 - II. 数组中数字出现的次数 II 解法一：遍历统计每个bit 1 出现的次数，最后对 3 取模即可。 解法二：还有个位运算的解，感觉没必要这么取巧。 剑指 Offer 57 - II. 和为s的连续正数序列滑动窗口，[i, j]表示连续子数组的两端，临时sum &lt;&gt; s，j右移扩大窗口，否则 i 左移缩小窗口。 剑指 Offer 58 - I. 翻转单词顺序split一下，然后倒序数组，最后拼接。 剑指 Offer 58 - II. 左旋转字符串切片操作，不做赘述。 剑指 Offer 59 - I. 滑动窗口的最大值这题标记为 easy 过分了。暴力解法就不说了，时间复杂度是 O(k*N)。可以优化一下，使用单调减的辅助队列（类似单调栈），来减少求每个窗口最大值时的遍历情况。复杂度为O(N)，因为辅助队列里的每个数，平均跟新进入队列的数，比较1次。（因为要么直接加入队列，要么，删掉队尾比它小元素，加入队列），被删掉的元素只会被比较 1 次。考虑极端情况，每个数都会加入辅助队列（原数组是递减的），则每次仍只需比较队尾元素和新加入元素 1 次。因此比较了 2N 次PS：单调栈和单调队列，是一个非常有帮助的思路。 剑指 Offer 59 - II. 队列的最大值类似 剑指 Offer 30. 包含min函数的栈，同样使用单调减的辅助队列。这题也可以称为”包含max函数的队列“。 剑指 Offer 60. n个骰子的点数这个题目描述得实在不好理解。 你需要用一个浮点数数组返回答案，其中第 i 个元素代表这 n 个骰子所能掷出的点数集合中第 i 小的那个的概率。 不过，写到这里，我发现用文字去描述一个算法思想，确实不太容易。至于这题，举个栗子，比如两个骰子，那么依次输出，抛出骰子的和为 2、3、4、5、6 …的概率。 首先可知，有 n 个骰子，那么结果范围为 [n, 6*n]，那么利用动态规划思想： 划分子问题：使用n个骰子抛出 x 的概率，等于使用一个骰子抛出 a 的概率 乘以 n-1 个骰子，抛出 x-a 的概率。一个骰子抛出各个值的概率自然是 1/6 状态转移公式：dp(n, x) = 1/6 * dp(n, x-a), 其中 a in [1, 6] 边界条件：dp(1, a) = 1/6，其中 a in [1, 6] 剑指 Offer 61. 扑克牌中的顺子除下0之外，数组不能重复。同时计算数组的最小值、最大值。（除 0 以外）判断 max_val - min_val 是否 &lt;= 4。 剑指 Offer 62. 圆圈中最后剩下的数字约瑟夫环，这特么竟然标记为简单！！！ 说是hard真不算过分。因为输出是最后剩下的数字，也正好是其下标。约瑟夫环的关键在于递推公式: F(N, M) = (F(N-1, M) + M) % N 其中，F(N,M)表示 N 个人时，某未被删除的数字的下标。假设 F(N,M) = y，在经过一次删除操作后，y的下标变为了 (y-M)%(N-1)，即 F(N-1, M)，设为 x。（因为 N 个数时，删除 M，会从第 M+1 处重新从 0 计算下标。被删除的 M 处于新数组的队尾，因此不会因为空洞之类的原因，影响新的下标计算。）根据 (y-M)%(N-1)=x 可推得： y = (x + M) % N 其实也好理解，相当于删除的逆过程，x左移M个位置，然后对N取余。 已知，F(1, M) = 0，因为1个人的时候，剩下数字的下标就是 0，那么可以递推出 F(1, M)，F(2, M) 直到 F(N, M)。 123456class Solution: def lastRemaining(self, n: int, m: int) -&gt; int: if n==1: return 0 return (m + self.lastRemaining(n-1, m)) % n 剑指 Offer 63. 股票的最大利润这个显然算 easy，却标记为 middle。不再啰嗦。 剑指 Offer 64. 求1+2+…+n这个妙在，利用 and / or 操作的执行顺序。已知： A and B，如果 A 为false，则 B 不会再执行 A or B，如果 A 为true，则 B 不会再执行 123456789101112class Solution: def sumNums(self, n: int) -&gt; int: self.res = 0 def sum(n: int): _ = n != 1 and self.sumNums(n - 1) # _ = n == 1 or self.sumNums(n - 1) self.res += n return True sum(n) return self.res 剑指 Offer 65. 不用加减乘除做加法这个特么又标为easy就离谱，里面的细节一点不少。两个数的相加，在二进制上可以表现为两部分： 直接相加，忽略进位：s1 = a ^ b，相同为0，不同为1 进位部分：s2 = (a &amp; b) &lt;&lt; 1，同为1的位，要向左进一位 两部分相加：sum = s1 + s2 剑指 Offer 66. 构建乘积数组使用两个辅助数组，分别计算从左到右，以及从右至左的乘积。再优化一下，可以只使用一个辅助数组。 剑指 Offer 67. 把字符串转换成整数难点在于检查中间结果是否溢出的条件，两种情况： res &gt; INT_MAX // 10，此时 res * 10，肯定溢出了 res == INT_MAX // 10 and cur_num &gt; 7，因为INT_MAX = 2147483647，如果 res 是正数，显然越界；如果 res 是负数，INT_MIN = -2147483648，所以满足这个条件的，只有 INT_MIN 本身。 剑指 Offer 68 - I. 二叉搜索树的最近公共祖先先分析下问题： 如果 p == root 或 q == root，那么 root 本身就是最近公共祖先 如果 p &lt; root &lt; q，那root一定是最近公共祖先 如果不满足 1，那么p和q 一定同时在 root 的左子树或右子树 上述root可能是某棵子树的根节点。 剑指 Offer 68 - II. 二叉树的最近公共祖先先分析下问题： 这是一棵普通二叉树，非搜索二叉树，各节点是无序的 最近公共祖先的定义不变，对于某节点来说，p/q 分别位于其左右子树；或其为p或q，并且q或p在其子树上；该节点就是最近公共祖先。 123456789101112131415161718192021222324class Solution: def lowestCommonAncestor(self, root: TreeNode, p: TreeNode, q: TreeNode) -&gt; TreeNode: if root is None: return None # 你可能有疑问，不用确定另一个在不再它的子树里吗？无需确定 # 假如root=p，若q在其子树里，root即为最近公共祖先； # 若q不在其子树里，那一定在别的子树里，此时会有left_res和right_res都不为None的时候，也就会返回对应的root if root.val == p.val or root.val == q.val: return root left_res = self.lowestCommonAncestor(root.left, p, q) right_res = self.lowestCommonAncestor(root.right, p, q) # p, q分别位于root的左右子树，root本身就是解 if left_res is not None and right_res is not None: return root # 到这里，left_res 和 right_res 一个为None，一个不为None # 情况1：某子树root==p或q，因此返回了自己，此时最近公共祖先，就是该子树的root。 # 就是left_res或right_res中不为空的那个。 # 情况2：某棵子树上发现了最近公共祖先，将其传递至最上层 return left_res if left_res else right_res 完结散花 ~","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"剑指offer题目思路简结-2","slug":"剑指offer题目思路简结-2","date":"2020-06-22T13:43:53.000Z","updated":"2020-06-22T13:43:53.000Z","comments":true,"path":"2020/06/22/剑指offer题目思路简结-2/","link":"","permalink":"http://yoursite.com/2020/06/22/%E5%89%91%E6%8C%87offer%E9%A2%98%E7%9B%AE%E6%80%9D%E8%B7%AF%E7%AE%80%E7%BB%93-2/","excerpt":"","text":"剑指 Offer 26. 树的子结构 剑指 Offer 27. 二叉树的镜像 剑指 Offer 28. 对称的二叉树 剑指 Offer 29. 顺时针打印矩阵 剑指 Offer 30. 包含min函数的栈 剑指 Offer 31. 栈的压入、弹出序列 剑指 Offer 32 - I. 从上到下打印二叉树 剑指 Offer 32 - II. 从上到下打印二叉树 II 剑指 Offer 32 - III. 从上到下打印二叉树 III 剑指 Offer 33. 二叉搜索树的后序遍历序列 剑指 Offer 34. 二叉树中和为某一值的路径 剑指 Offer 35. 复杂链表的复制 剑指 Offer 36. 二叉搜索树与双向链表 剑指 Offer 37. 序列化二叉树 剑指 Offer 38. 字符串的排列 剑指 Offer 39. 数组中出现次数超过一半的数字 剑指 Offer 40. 最小的k个数 剑指 Offer 41. 数据流中的中位数 剑指 Offer 42. 连续子数组的最大和 剑指 Offer 43. 1～n整数中1出现的次数 剑指 Offer 44. 数字序列中某一位的数字 剑指 Offer 45. 把数组排成最小的数 剑指 Offer 46. 把数字翻译成字符串 剑指 Offer 47. 礼物的最大价值 剑指 Offer 48. 最长不含重复字符的子字符串 剑指 Offer 49. 丑数 剑指 Offer 26. 树的子结构DFS判断各个子树，是否满足子树条件即可。树的结构，天生适合递归。 剑指 Offer 27. 二叉树的镜像递归交换左右子树的左右节点。 剑指 Offer 28. 对称的二叉树递归判断左右子树的左右节点。 剑指 Offer 29. 顺时针打印矩阵像洋葱一样，一层一层剥离打印。注意一些特殊情况，比如矩阵只有一行、一列的情况 剑指 Offer 30. 包含min函数的栈关键在于min的复杂度要求O(1)。这里需要用一个单调递减的栈，辅助实现。\b单调栈、单调队列在处理一些栈、队列最大值、最小值上很有用。 剑指 Offer 31. 栈的压入、弹出序列用一个栈去模拟压入、弹出过程，每当pop[0]==stack[-1]时，stack就弹出。如果pushed进栈完后，stack里还有数，则说明序列不对。 剑指 Offer 32 - I. 从上到下打印二叉树类似BFS，使用一个队列保存当前level的节点，之后依次遍历。 剑指 Offer 32 - II. 从上到下打印二叉树 II类似 剑指 Offer 32 - I. 从上到下打印二叉树，每层的结果单独保存即可。 剑指 Offer 32 - III. 从上到下打印二叉树 III类似 剑指 Offer 32 - I. 从上到下打印二叉树，每层的结果单独保存即可。使用一个flag来判断顺序还是逆序。 剑指 Offer 33. 二叉搜索树的后序遍历序列根据root节点，划分左右子树，递归判对即可。 剑指 Offer 34. 二叉树中和为某一值的路径递归DFS 剑指 Offer 35. 复杂链表的复制这题有意思，难得见到一个有意思的链表类的题。思路步骤： 复制：对每个节点都复制一个节点，并添加在其后面 拆分：对复制后的链表进行拆分，由于已知每个节点后面跟的，都是其复制节点，因此只需将复制节点的指向，也指向对应节点的复制节点，即可。 剑指 Offer 36. 二叉搜索树与双向链表对二叉搜索树模拟中序遍历，用一个指针记录遍历过程中的pre节点，最后将首尾相连，即可。 剑指 Offer 37. 序列化二叉树这题标记为hard，但实际上应该只算得上middle。 序列化：类似层次遍历，与 剑指 Offer 32 - I. 从上到下打印二叉树 相似。 反序列化：还是模拟层次遍历的过程 剑指 Offer 38. 字符串的排列这种排列组合、枚举类题，都可以用回溯思想来解决。和DFS类似，其实DFS是回溯思想在树、图之类的特殊场景里的一种表现。同DFS，回溯的常见实现方式也是递归。递归的时候，要小心大量的重复计算。（动态规划的递归实现中也存在） 通常要进行剪枝操作。因此也和动态规划的实现类似，可以使用备忘录法，或自底向上法。自底向上法效率最高，因为常常可以用循环迭代方式实现，减少递归调用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution: # 递归回溯，执行时间700ms def permutation1(self, s: str) -&gt; List[str]: if len(s) == 0: return [''] res = set() for i in range(0, len(s)): child_res = self.permutation1(s[:i] + s[i + 1:]) for v in child_res: res.add(s[i] + v) return list(res) # 备忘录，执行时间120ms def permutation2(self, s: str) -&gt; List[str]: seen = &#123;&#125; def perm(s2): if len(s2) == 0: return [''] if s2 in seen: return seen[s2] # 递归过程不变 res = set() for i in range(0, len(s2)): child_res = perm(s2[:i] + s2[i + 1:]) for v in child_res: res.add(s2[i:i + 1] + v) seen[s2] = list(res) return list(res) sorted_s = ''.join(sorted(s)) return perm(sorted_s) # 自底向上，执行时间80ms def permutation3(self, s: str) -&gt; List[str]: if len(s) == 0: return [''] res = set(s[0]) for c in s[1:]: new_set = set() for item in res: for i in range(0, len(item)+1): new_item = item[0:i] + c + item[i:] new_set.add(new_item) res = new_set return list(res) 剑指 Offer 39. 数组中出现次数超过一半的数字遍历一遍数组，记录一个数，及其出现次数。 剑指 Offer 40. 最小的k个数经典题目，两种解法： 利用容量为K的大顶堆，遍历一遍即可，比堆顶元素小的入堆，容量超过K时出堆 利用快排的二分思路，每次可以排除一批不满足条件的数，从而快速缩小查找范围 解法的关键思想在于，找最小的k个数，但是这k个数互相是不必排序的，因此尽力减少这部分排序操作。堆就减少了内部各个元素互相排序的操作。同样快排的二分思想，也可以一下子找到最大的m个数，m取决于所选的pivot。但是这m个数只需跟pivot比较，相互之间无需比较。 剑指 Offer 41. 数据流中的中位数这个有点妙。 使用两个堆，一个使用小顶堆，保存较大的一半数字；一个使用大顶堆，保存较小的一半数字。同时保持两个堆的元素数量相对平衡 0 &lt;= (大堆-小堆) &lt; 1。此时两个堆的堆顶元素，就是数据流中间的两个数。 在push时，将其和堆顶元素比较选一个堆加入。如果加入后，两个堆失去平衡，则进行调整 取中位数时，根据两个堆元素数是否相等可知，一共有奇数或偶数个数字。从而根据堆顶元素，计算中位数。 剑指 Offer 42. 连续子数组的最大和对于每一个元素，有两个选择，与前一个数字组成子数组，或重新开始计算子数组。记录遍历过程中的最大值。 剑指 Offer 43. 1～n整数中1出现的次数按个位、十位、百位…考虑，比如：输入314，分析过程如下 个位4，&gt;1，高位为31，受此影响，有 32 * 1 = 32 种可能 十位1，=1，高位为3，低位为4，受此影响，有 3*10 + 5 = 35 种可能 百位3，&gt;1，高位为0，受此影响，有 1*100 = 100 种可能 因此一共 32 + 35 + 100 = 167个。关键在于梳理清各种情况下1的个数。比如十位为1时，那么有01x/11x/21x，以及310~314，这么多种，也就是 3*10+5 = 35种。对于百位，当百位为1时，有1xx这么多种情况，所以就是 1 * 100种。 剑指 Offer 44. 数字序列中某一位的数字和 剑指 Offer 43. 1～n整数中1出现的次数 类似，关键在于找规律。可以发现:忽略0数字为1位的，从 1 开始，一共 9 个，1 - 9数字为2位的，从 10 开始，一共 90 个，10 - 99数字为3位的，从 100 开始，一共 900 个，100 - 999…依此可确定，第n位所在的区间，在取模可得到具体是哪个数字。大致思想如上，实现细节不再赘述。 剑指 Offer 45. 把数组排成最小的数一个取巧的办法，对数组进行自定义排序，从小到大。对于a、b两数的比较规则是，如果ab&gt;ba，则a&gt;b，否则a&lt;b。 剑指 Offer 46. 把数字翻译成字符串按动态规划的方式比较好理解： 划分子问题：每一位数字，既可以单独表示一个字母，也可以与后面数字组合，共同表示一个字母，如果&lt;26的话。 状态转移公式：F(s) = F(s[1:]) + F(s[2:]) 边界条件：len(s)&lt;=1时，F(s) = 1; 为什么 s 是空字符串时，F(s)也=1呢，s为空字符串，表示刚好划分完，仅此一种。比如12，F(12) = F(2) + F(“”)，F(“”)表示，12作为一个整体解释。 剑指 Offer 47. 礼物的最大价值很基础的动态规划题：按动态规划的方式比较好理解： 划分子问题：每一个格子可以分为，从上边格子和左边格子过来两种情况 状态转移公式：dp[i][j] = max(dp[i-1][j]+grid[i][j], dp[i][j-1]+grid[i][j]) 边界条件：第一行和第一列，单独处理 另外可以发现，dp[i][j]只和上一行有关，因此为了降低空间复杂度，可以只用一行空间即可。对 M*N 的格子，空间复杂度可以从 O(M * N) 降低至 O(M) 或 O(N) 剑指 Offer 48. 最长不含重复字符的子字符串使用两个指针 i, j，分别表示起始和结束。同时记录、更新某字符上次出现的位置。如果 j 指向的当前字符，上次出现的位置 k &gt; i，表示重复出现，则 i 更新为 k + 1。此时得到一个最长不重复子字符串，长度为 j-i。 剑指 Offer 49. 丑数下一个丑数为，当前丑数序列 * 2、3、5，得到的丑数中，最小的那个。为了避免重复计算，可以使用三个数，分别记录上一个乘以2、3、5后，就大于最新丑数的位置。 1234567891011121314151617181920212223class Solution: def nthUglyNumber(self, n: int) -&gt; int: if n == 1: return 1 dp = [0] * n dp[0] = 1 a, b, c = 0, 0, 0 for i in range(1, n): # 计算下一个丑数 aN, bN, cN = dp[a] * 2, dp[b] * 3, dp[c] * 5 # 选最小的 next = min(aN, bN, cN) dp[i] = next if next == aN: a += 1 if next == bN: b += 1 if next == cN: c += 1 return dp[-1]","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"剑指offer题目思路简结-1","slug":"剑指offer题目思路简结-1","date":"2020-06-22T06:54:13.000Z","updated":"2020-06-22T06:54:13.000Z","comments":true,"path":"2020/06/22/剑指offer题目思路简结-1/","link":"","permalink":"http://yoursite.com/2020/06/22/%E5%89%91%E6%8C%87offer%E9%A2%98%E7%9B%AE%E6%80%9D%E8%B7%AF%E7%AE%80%E7%BB%93-1/","excerpt":"","text":"剑指 Offer 03.数组中重复的数字 剑指 Offer 04. 二维数组中的查找 剑指 Offer 05. 替换空格 剑指 Offer 06. 从尾到头打印链表 剑指 Offer 07. 重建二叉树 剑指 Offer 09. 用两个栈实现队列 剑指 Offer 10- I. 斐波那契数列 剑指 Offer 10- II. 青蛙跳台阶问题 剑指 Offer 11. 旋转数组的最小数字 剑指 Offer 12. 矩阵中的路径 剑指 Offer 13. 机器人的运动范围 剑指 Offer 14- I. 剪绳子 剑指 Offer 14- II. 剪绳子 II 剑指 Offer 15. 二进制中1的个数 剑指 Offer 16. 数值的整数次方 剑指 Offer 17. 打印从1到最大的n位数 剑指 Offer 18. 删除链表的节点 剑指 Offer 19. 正则表达式匹配 剑指 Offer 20. 表示数值的字符串 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面 剑指 Offer 22. 链表中倒数第k个节点 剑指 Offer 24. 反转链表 剑指 Offer 25. 合并两个排序的链表 剑指 Offer 03.数组中重复的数字直接使用hash即可，高级一点的使用bitmap也可 剑指 Offer 04. 二维数组中的查找关键在于，利用规律缩小查找范围。 如果target &lt; 当前的数，那么它就不可能在target同一行的左边 每一列都按照从上到下递增的顺序排序：那么如果target &gt; 当前的数，那么它就不可能在target同一列的上面 从右上角开始找，一点一点缩小范围。 剑指 Offer 05. 替换空格 如果用python/java/golang之类的，可以直接拼接字符串。动态分配内存。 如果用c/c++，就需要预分配内存，因此需要先遍历一遍，计算有多少个空格，从而计算结果字符串所需内存大小。 剑指 Offer 06. 从尾到头打印链表 解法一：先遍历，再对结果数组反转 解法二：使用栈暂存节点，然后弹出栈 剑指 Offer 07. 重建二叉树关键点： 前序遍历的第一个节点，是当前节点的root；但是没法区分剩余节点，哪些是左、右子树 根据root，可以把中序遍历，分为左右子树两部分；借此得知左右子树的节点数量，也就能把前序遍历剩余节点分开 对前序遍历拆分的左右子树，递归求解 剑指 Offer 09. 用两个栈实现队列关键点： 两个栈，一个是input栈，一个是output栈，分别只负责input和output output没了，就从input里转移到output 时间复杂度，O(1)；空间复杂度，O(n) 剑指 Offer 10- I. 斐波那契数列递归、迭代解法，不再赘述。值得一提的是，对于递归类题目，有两个关键点： 递归子问题 递归终止条件，这个不能忘 尤其是二叉树类的问题，天生合适递归。把一个二叉树的问题，转换为，分别针对左右子树的两个子问题。 剑指 Offer 10- II. 青蛙跳台阶问题同 剑指 Offer 10- I. 斐波那契数列 斐波那契数列。 剑指 Offer 11. 旋转数组的最小数字二分法，确定min_index在[left, mid]，还是在[mid, right]之间。注意下极端条件，比如：翻转0个的情况；所有数都相等的情况；最后剩余两个数的情况；mid和边界相等的情况等等 剑指 Offer 12. 矩阵中的路径DFS 剑指 Offer 13. 机器人的运动范围BFS，当然DFS也可以，不过BFS最合适，相当于一圈一圈地扩展范围 剑指 Offer 14- I. 剪绳子简单的动态规划，顺带提一下动态规划的三个关键点： 划分子问题：一个大问题可以拆分为多个小问题，并且在大问题是最优解时， 状态转移公式 边界条件 是不是很像递归，因为动态规划一个最简单的实现方式就是递归。对于该题，三个关键点分别是： 划分子问题：长度为n的绳子，最大乘积，等于将其分一部分、两部分、多部分的最大值。 状态转移公式：F(n) = max( (n-i) * F[i] for i in range(1, n)) 边界条件：F(0) = 1; F(1) = 1 另外，由于该题要求至少分两段，因此需要对长度为最长时，稍微做一点特殊处理。 如果是递归实现，是会提示超时的，因为其中存在很多重复的计算。可以用递归的另外两种实现方式：备忘录法，自底向上法。 还有一种解法是根据数学规律，将n分为尽量多个3。这种解法不具通用性，就不介绍了。 剑指 Offer 14- II. 剪绳子 II在 剑指 Offer 14- I. 剪绳子 基础上，多了大数，就直接使用long类型，然后取模吧。 剑指 Offer 15. 二进制中1的个数经典位运算题。n的每一位与 1 做 与操作，直到n变为0。 剑指 Offer 16. 数值的整数次方关键点，利用二分思想： 12pow(x, n) = pow(x, n//2) ** 2 # n为偶数 pow(x, n) = pow(x, n//2) ** 2 * x # n为奇数 剑指 Offer 17. 打印从1到最大的n位数最大的n位数，是 pow(10, n)-1，遍历即可。小心大数越界，如果是面试。 剑指 Offer 18. 删除链表的节点不再赘述。值得一提：链表类问题，可以增加一个头结点dummy_head，这样可以使边界情况，处理起来方便很多。 剑指 Offer 19. 正则表达式匹配动态规划：（主串S, 模式串T） 划分子问题：如果S和T匹配，那么S和T的子串也匹配 状态转移公式：为了避免每次都要检查，后一个字符串是否是”*”，从后往前遍历。 123456789101112131415161. T[i] 是普通字符 F(S, T) &#x3D; S[i] &#x3D;&#x3D; T[i] &amp;&amp; F(S[:-1], T[:-1])2. T[i] &#x3D;&#x3D; &#39;.&#39;，可以匹配任何字符 F(S, T) &#x3D; F(S[:-1], T[:-1])3. T[i] &#x3D;&#x3D; &#39;*&#39;，*前面的字符可以重复0次或多次 3.1 S&#x3D;&#x3D;&quot;&quot;, 说明*前面的字符重复0次 F(S, T) &#x3D; F(S, T[:-2]) 3.2 T[-2] &#x3D;&#x3D; &#39;.&#39; 或 S[-1] &#x3D;&#x3D; T[-2]，前一个字符能匹配上，则需考虑匹配0次、和多次的情况 F[S, T] &#x3D; F(S, T[:-2]) || F(S[:-1], T) 3.3 S[-1] !&#x3D; T[-2]，前一个字符不匹配，相当于匹配了0次 F(S, T) &#x3D; F(S, T[:-2]) 边界条件:边界条件，就是S、T一直递归匹配，直到某一个变为了空字符串 123451. S &#x3D;&#x3D; &quot;&quot; &amp;&amp; T &#x3D;&#x3D; &quot;&quot;，return True2. S &#x3D;&#x3D; &quot;&quot; &amp;&amp; T !&#x3D; &quot;&quot;, 需要继续匹配，比如 S&#x3D;”“， T&#x3D;&quot;a*&quot;，是匹配的3. S !&#x3D; &quot;&quot; &amp;&amp; T &#x3D;&#x3D; &quot;&quot;, return False 剑指 Offer 20. 表示数值的字符串非常典型的一道有限状态机题，重点在于划分不同的状态，怕错不怕重复。状态之间的转移相对容易。 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面两个指针，pre指针从头开始遍历，post指针指向尾。每次pre指向一个偶数，就将其与post交换，直到两指针相遇。 剑指 Offer 22. 链表中倒数第k个节点快慢指针，不做赘述。 剑指 Offer 24. 反转链表三个指针，循环遍历即可。注意边界条件。 剑指 Offer 25. 合并两个排序的链表添加一个dummy头结点，然后对两个链表，执行类似一个归并排序的操作。","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"人生的一些大道理","slug":"人生的一些大道理","date":"2020-06-11T08:25:13.000Z","updated":"2020-06-11T08:25:13.000Z","comments":true,"path":"2020/06/11/人生的一些大道理/","link":"","permalink":"http://yoursite.com/2020/06/11/%E4%BA%BA%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A4%A7%E9%81%93%E7%90%86/","excerpt":"","text":"Respect ！","categories":[],"tags":[]},{"title":"从CAS到无锁队列.md","slug":"从CAS到无锁队列","date":"2020-06-03T09:24:15.000Z","updated":"2020-06-03T09:24:15.000Z","comments":true,"path":"2020/06/03/从CAS到无锁队列/","link":"","permalink":"http://yoursite.com/2020/06/03/%E4%BB%8ECAS%E5%88%B0%E6%97%A0%E9%94%81%E9%98%9F%E5%88%97/","excerpt":"","text":"无锁算法多个线程读写同一内存，如何做到不加锁呢？其实没有那么高大上的算法在里面，实现无锁的前提是，硬件需支持”读取-更新-写入“的原子操作，比如 Test and Set, Fetch and Add, Compare and Swap等。以Compare and Swap，也就是CAS为例，可以实现很多无锁的数据结构，无锁队列，无锁树，区别在于需要几次的CAS。 CASbool CAS(type* addr, type val_old, type val_new)如果 addr 的值等于 val_old，就把它设置为 val_new，设置成功返回true，失败返回false。这个比较并赋值的操作，是一个原子操作。 无锁队列我们使用一个单向链表，作为无锁队列的基础数据结构。利用CAS的原子性，来保证在push/pop，也就是在链表尾/头添加、删除节点时，不会出现多线程互相覆盖的问题。 直接看代码: 123456// 很久没写C/CPP，语法细节忘了不少，忽略忽略struct &#123; node* tail // 尾指针 node* head // 头指针&#125;* Q 12345678910111213141516// Q是队列，data是待push的节点Push(Q, data)&#123; while true &#123; p = Q-&gt;tail; if CAS(p-&gt;next, NULL, data) &#123; // 如果此时p还是Q的tail，才能设置成功 break &#125; &#125; // 更新Q的tail，如果此时tail还是p，才能设置成功。 // 此时不用担心失败，因为如果此处不更新tail，其他线程拿到的总是旧的tail， // 其他线程在while循环中的CAS，会发现p-&gt;next!=NULL，就会失败, 一直处于while循环中 CAS(Q-&gt;tail, p, data)&#125; 123456789101112Pop(Q)&#123; while true &#123; p = Q-&gt;head if CAS(Q-&gt;head, p, p-&gt;next) &#123; break &#125; &#125; return p-&gt;value&#125; 由于CAS会直接用新值覆盖旧值，为了保存旧值，所以每次都会先把旧值取出来。然后在设新值时，要判断旧值是否发生了变化。那么以上实现有什么问题没？ 问题1，死循环考虑一些意外的情况。对于Push，如果线程第一个CAS执行成功，在执行第二个CAS时宕掉。此时 tail 未更新，其他线程会发现tail.next总是不为空，因此就会陷入while死循环。 问题2，ABA问题比如，一个线程按序执行了 pop -&gt; push操作，而push的节点，恰巧复用了被pop节点同一块内存。因为此链表例子中，CAS比较的是内存地址，所以校验通过。而里面的值其实是发生了变化的，如果不校验里面的值，可能会认为节点未被改动。 这两个问题如何解决呢？ 死循环问题 关键：tail节点未更新，导致CAS(p-&gt;next, NULL, data) 总是失败，因此可以让每个线程发现这个问题后，自己去更新tail节点。 ABA问题 节点增加计数器，每一次更新。计数的增减操作也需要原子化。 总结无锁数据结构的大致思想就是这样。借助CAS，一个极端的想法，所有程序都可以做成无锁的。只需要对任何一个变量的读写，都使用CAS操作，失败则从头开始。此时，虽然实现了无锁，但是效率却是降低的，\b因此，无锁也有它的适用场景 — 读多写少。因此此时CAS的冲突率比较小。与CAS比较像的一个机制，是自旋锁。自旋锁总是在尝试加锁，而CAS总是在尝试比较-修改，都算是忙等机制。","categories":[{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"算法","slug":"后端/算法","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法思想","slug":"算法思想","permalink":"http://yoursite.com/tags/%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3/"}]},{"title":"PathEscape与QueryEscape","slug":"PathEscape与QueryEscape","date":"2020-05-29T04:56:52.000Z","updated":"2020-05-29T04:56:52.000Z","comments":true,"path":"2020/05/29/PathEscape与QueryEscape/","link":"","permalink":"http://yoursite.com/2020/05/29/PathEscape%E4%B8%8EQueryEscape/","excerpt":"","text":"在给client种cookie时，发现个问题，种进去的加密cookie，解密时总报错。原因是：golang中，对一个字符串做url转义有两个方法，url.PathEscape()和url.QueryEscape。但是两个方法的行为有些区别。两者混用导致，编码和解码后，和原始字符串不一致。 1. 举个例子，直接对比下效果以 + 和 空格 这两个字符为例。 待转义字符 PathEscape QueryEscape PathUnEscape QueryUnEscape + + %2B + 空格 空格 %20 + 空格 空格 2. 具体功能2.1 PathEscape对特殊字符串进行转义，以便其可以作为url路径的一部分。就是URL地址两个 / 之间的部分 2.2 QueryEscape对特殊字符串进行转义，以便其可以作为url query的参数，也就是 ？后面那一串kv。 2.3 对比 两者的共同点在于：都会将一些特殊字符，转义为%AB的形式。特殊字符的定义为，除a-z，A-Z，0-9，- _ ~ · , / ; ? 的字符。 不同点在于：对于一些特殊字符，转义行为不同。 字符 PathEscpae QueryEscape $ Y N &amp; Y N + Y N : Y N = Y N @ Y N 具体的可参考RFC文档（URI、URL的两篇）和Golang的源码。（Golang源码更简单直接） 3. 其他其他语言似乎没分得那么清，具体实现上也有一些区别，比如python/javascript，encode行为就和golang的不一致。总之，同一语言，如golang，QueryEscape编码后，一定要配合QueryUnEscape使用。 一些细节也不同，比如JS里的encodeURI和encodeURIComponent。可以理解为，encodeURI，是把参数当做一个完整的URI在编码，而encodeURIComponent是把参数当做URI的一个segment。 12345678910111213// JS里encodeURI(\"12+34 56\")output: \"12+34%2056\"encodeURIComponent(\"12+34 56\")output: \"12%2B34%2056\"var a = \"http://www.ruanyifeng.com/blog/2010/02/url_encoding.html\"encodeURI(a)output: \"http://www.ruanyifeng.com/blog/2010/02/url_encoding.html\"encodeURIComponent(a)output: \"http%3A%2F%2Fwww.ruanyifeng.com%2Fblog%2F2010%2F02%2Furl_encoding.html\" 参考： http://www.ruanyifeng.com/blog/2010/02/url_encoding.html https://tools.ietf.org/html/rfc1738 https://tools.ietf.org/html/rfc3986","categories":[],"tags":[]},{"title":"关于工作的一些想法.md","slug":"关于工作的一些想法","date":"2020-05-28T06:36:40.000Z","updated":"2020-05-28T06:36:40.000Z","comments":true,"path":"2020/05/28/关于工作的一些想法/","link":"","permalink":"http://yoursite.com/2020/05/28/%E5%85%B3%E4%BA%8E%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95/","excerpt":"","text":"待写。。","categories":[],"tags":[]},{"title":"常见web安全总结","slug":"常见web安全总结","date":"2020-05-25T08:20:55.000Z","updated":"2020-05-25T08:20:55.000Z","comments":true,"path":"2020/05/25/常见web安全总结/","link":"","permalink":"http://yoursite.com/2020/05/25/%E5%B8%B8%E8%A7%81web%E5%AE%89%E5%85%A8%E6%80%BB%E7%BB%93/","excerpt":"","text":"XSS，跨站脚本攻击XSS的根本原因是，前端页面被嵌入一些恶意代码，这些恶意代码可能通过不同途径，注入进来。根据不同注入途径（或着说方式），可以分为反射型、持久型。 反射型XSS 恶意伪造url -&gt; 骗取用户点击 -&gt; 页面从url取参数进行渲染。从而参数里的恶意代码被执行。 案例：微博hellosamy事件 持久性XSS 在留言板、评论等场景提交恶意代码 -&gt; 后台未经处理，直接保存了前端提交的数据，-&gt; 再次访问或其他人访问时，前端展示相关内容，又把这些数据取出来进行渲染，从而恶意代码被执行。 案例：微信公众号XSS事件 应对： 用户提交的数据，入库前预处理，很多xssfilter 前端拼接Html时，也要做充分转义 为了防止cookie盗用，重要cookie设置http-only为true 参考 https://tech.meituan.com/2018/09/27/fe-security.html CSRF，跨站请求伪造（英語：Cross-site request forgery）本质是浏览器在发起请求时，会自动带上对应域名下的cookie。该特性可能导致，用户在访问恶意网站时，在用户不知不觉的情况下，触发一些携带了用户身份信息（cookie）的请求。如下图所示： 银行网站A，它以GET请求来完成银行转账的操作，如：http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000 危险网站B，它里面有一段HTML的代码如下： &lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt; 首先，你登录了银行网站A，然后访问危险网站B，噢，这时你会发现你的银行账户少了1000块…… 在访问危险网站B的之前，你已经登录了银行网站A，而B中的img以GET的方式请求第三方资源（这里的第三方就是指银行网站了，原本这是一个合法的请求，但这里被不法分子利用了），你的浏览器会带上你的银行网站A的Cookie发出Get请求，去获取src指向的资源，结果银行网站服务器收到请求后，判断身份通过，所以就立刻进行转账操作…… 该例子里，一方面是由于用户上了小网站，另一方面，不应该用GET请求去更新资源（更改账户）。因为像src/script等标签都是默认用GET获取资源，如果再对前端熟悉一些的，可能会想到jsonp，就是利用script标签实现的。很多邮箱图片默认不展示，CSRF也是原因之一。当然还有很多其他的风险，这个可以单开一篇，开开脑洞。 vs 跨域？很多人会有疑问，浏览器不是有跨域限制吗，为什么还会出现在A页面，访问B服务器的情况。对于跨域请求，浏览器还是会正常发出，收到response后，会判断源和当前页面的源是否是属于同源，如果不属于，则需要根据access-control-allow-origin等header，判断server端是否允许跨域。 应对主要通过两个关键点： 虽然A网站可以向B服务器发请求，但是由于跨域限制，没法处理对应的response。因此一些更新资源的操作，最好用POST，更好的是使用restful风格。另一方面，也可以增加二次确认，比如引入验证码，实际上相当于一个动态的token。 由于正规的浏览器，对cookie访问，也要求同源。因此可以再query里增加一些cookie里才有的信息，在服务端校验query和cookie里对应的参数，如果不一致则为恶意。 其他的方法，还有增加referer，但是有的时候请求不带referer，比如非http协议页面发出的请求（ftp之类的）、https页面发出的http请求等，因此该方法有一定的漏洞。 SQL注入关键点： 1. 不要相信请求携带的参数，不要直接拿过来拼接SQL语句。SQL注入的防范很成熟，使用prepare statement即可，常用的client lib里都会实现。但是表名不支持参数化，因此表名还是得使用代码拼接的方式。这就要求表名不能是前端输入的，或者增加表名白名单校验。 从一条sql执行过程来说，编译 -&gt; 执行。一般情况是连带参数，一起编译，就会出现注入情况。 使用参数化查询的形式，会提前对模板进行预编译，而每个?占位的参数，只会被数据库当做一个完整的参数处理。","categories":[{"name":"安全","slug":"安全","permalink":"http://yoursite.com/categories/%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"MySQL知识点","slug":"MySQL知识点","date":"2020-05-20T03:09:35.000Z","updated":"2020-05-20T03:09:35.000Z","comments":true,"path":"2020/05/20/MySQL知识点/","link":"","permalink":"http://yoursite.com/2020/05/20/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"范式与反范式 范式 描述 反例 第一范式 每个字段都是原子的，不能再分解 某个字段是json串 第二范式 1. 表必须有主键；2. 非主属性，必须完全依赖主键，而不能只依赖主键的一部分字段。 好友关系表，关注人ID+被关注人ID作为主键，还存储了关注人的头像，这个只依赖于主键的一个字段。 第三范式 非主属性，直接依赖主键，而非间接依赖。 员工表，有部门ID和部门名称等，部门名称依赖部门ID，而不是员工ID，不应在员工表中。 分库分表比如电商订单表，有三个查询纬度：订单ID，用户ID，商户ID。 建立主纬度和辅助纬度之间的一个映射表比如，以订单ID拆分，那么要保存用户ID-&gt;订单ID和商户ID-&gt;订单ID的映射表。然而问题是： 映射表本身也要分表 每个订单，要写入多个库，属于分布式事务问题。通常会由后台任务，定时对比，保证多库表最终一致。 业务双写存多份数据，但是拆分纬度不一样。一套按用户ID划分，一套按商户号划分。同样存在写入多个库的分布式事务问题。 异步双写还是多份数据，业务单写一份，然后通过监听binlog，同步到其他表上 多个纬度统一到一个纬度比如把订单ID和用户ID统一成一个维度，然后把用户ID作为订单ID的一部分。这样，订单ID中就包含了用户ID的信息，然后按照用户ID分库，当按订单ID查询的时候，提取出用户ID，再按用户ID查询。 总之就是，拆分依据的维度，要同时在多个原始ID中提现 分库分表后的Join问题 join拆分为多个单表查询，在应用层代码里做join处理 增加宽表，提前join好 利用搜索引擎，比如ES，将DB数据导入ES中 分布式事务 最好是优化业务，避免跨库事务 如果无法避免，参考笔记：分布式事务一致性 B+树1. 优点相比hash索引，以及类似结构的KV缓存或数据库，有以下特性 范围查询 前缀匹配，模糊查询 排序和分页 2. 物理结构 磁盘属于块设备，innoDB读写磁盘，是以page为基本单位，page默认大小是16KB，每次I/O都是16KB的整数倍。 innoDB为每个Page赋予一个32位的全局编号，因此innoDB的存储上限是64T (2^32 * 16KB)。如果用来装非叶子节点，假如key是64位整数，也就是8字节，加上其他字段，按16字节算，一个page可以装1000个key。基于此估算，一个三层的B+树，可以存储的数据量： 第一层：根节点，一个page，1000个key。16KB内存，对应1000个子节点 第二层：1000个节点，每个节点一个page，每个page又可以有1000个子节点。16MB内存，对应1000 * 1000个子节点 第三层：1000 * 1000个节点，每个节点一个page。那么该表的最大容量是：1000 * 1000 * 16KB = 16GB。只需要16MB的内存索引，只需要一次I/O读取叶子节点 叶子page内部，以单向链表的方式，存储一条条的记录 非主键索引，索引树叶子节点存的是主键的value。 事务与锁1. 隔离级别 隔离级别 解决问题 Read Uncommited Read commited 解决脏读 Repeatable Read 解决幻读（通过间隙锁），innoDB默认级别。MVCC需要结合行锁，实现当前读，解决update时的覆盖问题。 Serialization 2. 死锁检测 判断一个有向图是否存在环，dfs、拓扑排序 死锁的发生，与代码有关，也与事务隔离级别有关，因为隔离级别会影响加锁机制。 复杂度是O(N) 3. innoDB的MVCC实现 每一行都有两个隐藏列，最近修改的事务ID + undolog里回滚段指针（便于回滚） 一致性视图，{low_trx_id, up_trx_id, trx_ids} low_trx_id: 当前事务链表，最小的事务id up_trx_id: 当前事务链表，最大的事务id trx_ids: 正在执行的事务的id集合通过比较当前事务id，与以上三个变量的关系，确定某个版本数据，是否对当前事务可见。 4. 事务实现1. WAL, Write-Ahead Log内存操作数据 + write-ahead log 2. Redo Log的逻辑与物理结构 redo log 物理组成结构 一个逻辑事务 包含 多个物理事务mtr，Mini Transaction 每个mtr对应一个LSN 一个LSN对应若干个连续的block 这些block，最终组成了 redo log 综上，一个事务在redo log里，可能有多个LSN，这些LSN自己是连续的，但是多个LSN不一定是连续的。 redo log 日志内容格式 先以page为单位记录日志 在每个page里面再采用物理记法 比如 (page id, record offset, (field1, value1)..(fieldi, valuei)…) Aries恢复算法 分析阶段从上一个checkpoint开始，开始分析哪些事务执行完了，未刷写page；哪些事务执行了一半，需要回滚。checkpoint机制，可以加快分析速度 redo阶段对已经commit的事务，执行redolog，刷写page。redolog是幂等的，重复执行没关系。 undo阶段对于未commit的事务，执行undolog，回滚 其他 每个page上记录了，上次修改的LSN，因此恢复时，如果redolog里的lsn&lt;page lsn，说明不用重写了。 redolog保证的是事务的持久性，写入成功，则不会丢失 3. Undo log redolog按LSN的顺序，而undolog没有顺序，多个事务并行写。每条日志除下记录主键ID和数据外，还有两个字段：修改记录的事务ID和回滚指针，用来串联所有历史版本，就是MVCC的两个隐藏列。 undo log 只在commit的过程中有用，一旦事务commit了，就可以删掉undo log 通俗一点，修改行前，先把行拷贝一份出来，这些历史版本形成一个链表。 各种锁 有不同的划分标准，比如按粒度，有表锁、行锁、gap锁；按锁的模式，有共享锁、排他锁、意向锁等 MySQL加锁问题与隔离级别有关，如果隔离级别是Read Commited，则不需要gap锁，因为RC允许幻读。 具体到各种锁 全局锁：对整个DB加锁，一些不支持事务的引擎，可以在备份前，锁住DB MDL，元数据锁：MDL分读/写，不需显式调用。MDL也是在语句执行时隐式加，在事务提交后释放。比如在对表做CURD时，加MDL读锁；对表做DDL时，加MDL写锁。 表锁，读/写，共享/排他，S/X 行锁，读/写，共享/排他，S/X 意向锁，意向锁也是表级别，但是意向锁之间互不排斥，包括IX（意向写）与IX也不互斥。意向锁的目的是提高在加表锁时的判断效率。如果事务要给表中某一行加X锁，首先要对表加IX锁；如果要给某一行加S锁，就先对表加IS锁。这也是“意向”一词的含义。如果一个事务要对表加X锁，就可以根据表有没有被其他事务加IS/IX锁，就可得知，有没有其他事务在读写该表。 间隙锁，解决幻读问题 AI锁，表级别，针对自增ID生成器，如果事务rollback，自增ID一列会不连续 其他问题 double write 机制 InnoDB的page size一般是16KB，其数据校验也是针对这16KB来计算的，将数据写入到磁盘是以page为单位进行操作的。操作系统写文件是以4KB作为单位的，磁盘IO是以512字节为单位的，那么每写一个InnoDB的page到磁盘上，操作系统需要写4个块。而计算机硬件和操作系统，在极端情况下（比如断电）往往并不能保证这一操作的原子性，16K的数据，写入4K时，发生了系统断电或系统崩溃，只有一部分写是成功的，这种情况下就是partial page write（部分页写入）问题。这时page数据出现不一样的情形，从而形成一个”断裂”的page，使数据产生混乱。这个时候InnoDB对这种块错误是无 能为力的. 有人会认为系统恢复后，MySQL可以根据redo log进行恢复，而MySQL在恢复的过程中是检查page的checksum，checksum就是pgae的最后事务号，发生partial page write问题时，page已经损坏，找不到该page中的事务号，就无法恢复。 为了解决该问题，写数据page时，写两遍到磁盘，第一遍是写到double write buffer文件上, 第二遍是从double write buffer写到真正的数据文件中。如果宕机重启，发现page损坏，可以从double write buffer中恢复。 因为redo log的写入单位就是512字节，也就是磁盘IO的最小单位，因此可以保证原子性，不会导致数据损坏。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"对CAP的正确理解","slug":"CAP","date":"2020-05-14T03:06:27.000Z","updated":"2020-05-14T03:06:27.000Z","comments":true,"path":"2020/05/14/CAP/","link":"","permalink":"http://yoursite.com/2020/05/14/CAP/","excerpt":"","text":"CAP C，一致性，多副本一致性，事务一致性等 A，可用性 P，分区容忍性 理解 最大的误解：CAP可以三选二实际上P是必然存在的，只能在C和A（一致性和可用性）之间权衡。实际中大多是AP或CP系统，很少有CA的系统。 AP系统，追求可用性，放弃一致性。比如MySQL主从等。 CP系统，追求强一致性，牺牲一定的可用性。raft、zab协议。而此时的一致性，也只是对客户端看来是一致的，对内部看，是最终一致，因为同步数据总需要时间。 对于CA系统，因为要实现A（高可用），就必然有冗余，有冗余就必然存在P。比如MySQL，内部事务实现强一致性C，但是单机无法保证A，单机也不存在网络延迟，因此可以满足P。 只要引入冗余，实现的高可用（A），就一定存在P。如果还想兼顾一致性（C），那么一定不是真的A。因此实际系统中，总是在CA之间做权衡。放弃某一方，就变成了AP或CP。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Map并发安全实现原理","slug":"map并发安全实现原理","date":"2020-05-14T03:03:32.000Z","updated":"2020-05-14T03:03:32.000Z","comments":true,"path":"2020/05/14/map并发安全实现原理/","link":"","permalink":"http://yoursite.com/2020/05/14/map%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","excerpt":"","text":"Java Concurrent hashmap 多个segment，支持最大segment数量的并发访问 ps: 如果hash桶的list过长，可以使用红黑树代替list golang sync.Map read-only, dirty 两个字段将读写分离 read-only不需加锁，读或写dirty都需要加锁 misses字段，统计read-only穿透次数，超过一定次数将dirty同步到read-only上 删除时，通过给read-only添加标记，延迟删除 读的时候，先查询read，不存在时查询dirty；写入时则只写入dirty 写入过程，每次写入时，先copy 未删除的read-only到dirty中，然后将k-v存入dirty。 read-only可以当做dirty的缓存。dirty里的数据，总比read-only的多。 适用于读多写少的场景。写入较多时，性能无法保证。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"各种树结构","slug":"各种树结构","date":"2020-05-13T02:21:07.000Z","updated":"2020-05-13T02:21:07.000Z","comments":true,"path":"2020/05/13/各种树结构/","link":"","permalink":"http://yoursite.com/2020/05/13/%E5%90%84%E7%A7%8D%E6%A0%91%E7%BB%93%E6%9E%84/","excerpt":"","text":"B树 vs B+树 vs B*树 B树，B是指发明人的名字 平衡多路搜索树 保持键值有序，以顺序遍历 使用不完全填充的节点块，来加速插入和删除 节点块至少半满，提升空间利用率 B+树 VS B树 非叶子节点，只保存索引：从而可以减少索引树的大小，内存里可以保存更多的索引。由于每次都需要走到叶子节点，查询时间也更稳定。 叶子节点之间，增加链指针，方便遍历 B*树在B+树的基础上 非根和非叶子节点，增加指向兄弟的指针 插入时，如果节点已满，会检查兄弟节点是否满，未满，则向兄弟节点转移数据；已满，则从当前节点和兄弟节点，各拿出1/3数据，创建一个新节点。从而节点空间利用率更高，节点分裂的情况也减少。 红黑树 也是一种BST(二叉搜索树)，但是不要求完全平衡 牺牲部分平衡性，达到较快的插入和删除性能 使用场景：linux CFS调度，nginx timer等 vs B树: B树作为多路搜索，能够在树深较小的情况下，支持更多的数据节点。对于磁盘类操作，可以避免大量的随机IO（一个磁盘page，可以读取到更多的索引，类似MySQL），从而优化读写性能。而红黑树一般整棵树都在内存里，不涉及到磁盘操作，支持的数据量较小，但是由于各种操作优于BST，因此常用于涉及到排序、搜索的场景。比如CFS，为了保证公平调度，每次选取当前执行总时间最小的线程执行。 LSM，Log-Structured Merged Tree 核心思想：放弃部分读性能，提高写性能。 适用于kv存储。 内存中的memtable，磁盘上的sstable。读取的时候，需要遍历sstable，这里的 优化是，使用是bloom filter，确定一个Key是否在sstable里。 一般LSM-Trees会配合内存排序，内存里将写数据缓冲（通常是一个红黑树、跳表之类的结构）。等积累得足够多之后，使用归并排序将数据合并，写入磁盘。 应用：rocksDB，levelDB，hbase rocksDB：c++编写的kv存储引擎，基于levelDB改造 levelDB：kv存储引擎 hbase: 分布式存储，列数据库，应对大量数据（亿级以上） 这些思想类似lsm，但也有一些优化和改进，比如levelDB为了避免sstable过多，以及降低sstable合并过程中的开销，增加了level的概念。如果没有level，新sstable需要和旧的sstable比较，随着数据量的增多，新sstable需要和越来越多的sstable合并，从而效率降低。（如果每次合并后只留下一个大的sstable，效率一样会降低，因为涉及到插入操作。）有了level，上下层level，待比较的相关sstable数量将会得到控制。从而加快压缩、合并的过程。除下按分层合并，还有按大小合并，hbase使用该种方法。两种思想，一种是更新的和更老的合并，一种是更小的和更大的合并。 sstable会保存所有写入的值（K-V），新的value并不会覆盖旧的value，而是读取的时候，从新的segment开始找，找到就停下。压缩、合并的过程，就是保留新的value，去除旧的value的过程。另外，为了防止系统崩溃，数据丢失，也会使用额外的WAL日志。相当于每次写入，需要更新有序的memtable，以及append WAL日志。 Lucene(ES的索引引擎)，也是用了类似的思想存储它的倒排索引。首先根据类lsm思想找到单词对应的倒排索引值（文档ID列表），再根据文档ID，获取具体的文档。 参考资料 http://blog.fatedier.com/2016/06/15/learn-lsm-tree/ lsm vs b+树 查询过程为了快速查询，一个办法是建立hash索引，但是hash索引占用空间太大，而且不支持区间查询。另一个办法是，事先对数据进行排序，B+树，把排序的操作放在了写入的时候，读的时候便轻松一些。 写过程 但是B树面对高并发写的时候，压力很大。B树把所有的压力都放到了写操作的时候，从根节点索引到数据存储的位置，可能需要多次读文件；真正插入的时候，又可能会引起page的分裂，多次写文件。 LSM在写的时候，直接写入内存，然后利用红黑树保持内存中的数据有序，由后台线程定期或被触发，去merge和持久化到磁盘。也会使用WAL方式记录log，避免数据丢失。 当写比读多时，LSM树相比于B树有更好的性能。因为随着insert操作，为了维护B树结构，节点分裂。读磁盘的随机读写概率会变大，性能会逐渐减弱。LSM把多次IO，批量变成一次IO，复用了磁盘寻道时间，极大提升效率。 总结下，通常LSM树的写入更快，B树的读取速度更快。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"分布式锁","slug":"分布式锁","date":"2020-05-12T13:35:11.000Z","updated":"2020-05-12T13:35:11.000Z","comments":true,"path":"2020/05/12/分布式锁/","link":"","permalink":"http://yoursite.com/2020/05/12/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"redis set key val nx ex 优点：实现简单，性能好 缺点：超时时间不好控制，极端情况，会出现超时后，多个节点获取到同一把锁的情况。 问题 主从，redis主从采用异步复制，那么如果主机宕机，切换到从，会导致部分锁数据丢失。此时，多个client会拿到同一把锁。 如果锁没有设置超时，若client挂掉，则锁永远不会释放 如果锁设置了超时，若client阻塞或业务执行超时，也会导致多个client拿到同一把锁。 zookeeper 使用临时顺序节点，如果自己是子节点的第一个，则表示加锁成功。否则，watch上一个，如果上一个释放，表示轮到自己了。 优点：一般情况，不存在client宕机/超时问题，zk感知到client宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者取消自己的排队。 缺点：实现复杂，吞吐量不高 问题 因为zk使用心跳判断client是否在线，如果网络超时或者full GC等等，导致zk认为client宕机，则会释放锁。导致其他client同时获得该锁。但是这种情况很少见，相比之下，client处理超时这种更常见，这也是zk比redis方案好的原因。 mysql行锁 优点：不需引入额外中间件 缺点：吞吐量不高；也存在client宕机超时问题 总结 探测client是否宕机很难，如果因为超时，那就不应该释放锁。如果是因为宕机，那就应该释放锁。 没有完美的方案，实际场景中，分布式锁只应作为辅助手段，比如为了减少DB的压力等，不应仅靠它控制业务并发逻辑。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"方案总结","slug":"分布式/方案总结","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"高并发常见方案","slug":"高并发","date":"2020-05-12T13:29:38.000Z","updated":"2020-05-12T13:29:38.000Z","comments":true,"path":"2020/05/12/高并发/","link":"","permalink":"http://yoursite.com/2020/05/12/%E9%AB%98%E5%B9%B6%E5%8F%91/","excerpt":"","text":"高并发写 数据分片 数据库分库分表 JDK concurrentHashMap实现 kafka的partition ES的分布式索引 任务分片（计算） CPU的指令流水线 Map/Reduce Tomcat 1+N+M 网络模型：1个监听线程，N个IO线程负责对socket进行读写，M个worker对请求做逻辑处理。 异步化：异步接口、异步IO 短信验证码注册/登录 订单系统 广告计费系统，异步，多消息合并扣费 Kafka的Pipeline WAL技术 MySQL innoDB 的 redo log LSM树众多应用，levelDB等 批量 kafka的百万qps写入:partition分片，磁盘顺序写入，批量（leader/follower之间的批量，本地client之间的批量） mysql的group commit机制，对多事务的redo log批量flush 高并发读 加缓存 本地缓存/redis/memcached 增加副本冗余 MySQL master/slave CDN 静态文件加速 并发读 异步RPC 冗余请求，降低失败率","categories":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"方案总结","slug":"分布式/方案总结","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"多副本一致性","slug":"多副本一致性","date":"2020-05-12T03:23:33.000Z","updated":"2020-07-12T08:46:48.033Z","comments":true,"path":"2020/05/12/多副本一致性/","link":"","permalink":"http://yoursite.com/2020/05/12/%E5%A4%9A%E5%89%AF%E6%9C%AC%E4%B8%80%E8%87%B4%E6%80%A7/","excerpt":"","text":"同步本质每台机器都把收到的请求按日志存下来，各机器的日志文件保持一致。选择存储“事件流”，而非最终状态，原因是： 日志只有一种操作，append，相对简单 Paxos算法1. Basic Paxos 两个角色，Proposer 和 Acceptor，以及一个自增ID（n） 两个阶段，Propose阶段 和 Accept 阶段 Propose阶段 proposer广播消息，id为n，prepare(n) acceptor接收消息，如果n &gt; local N，则回复yes proposer收到半数以上的yes，开始广播，否则id自增，重新广播 Acctpt阶段 proposer广播消息, accept(n, value) acceptor接收消息，如果n &gt; loacal N，则持久化，返回yes proposer收到半数以上的yes，则结束。否则id自增，从proposer阶段重新开始。 两个问题 Paxos是个不断循环的2PC，有可能陷入死循环，所谓“活锁”。比如3个node同时propose，都收到no，又同时n++，继续propose，继续no 性能：每次写入，需要两次RTT + 两次写盘。两次RTT分别是Propose/Accept阶段。这两个阶段都会持久化一些变量，需要磁盘IO。 活锁问题 多点写入，变为单点写入。选出一个leader，只让leader当proposer。从而减少冲突。leader选取办法，比如每个节点增加编号，使用心跳，选取编号最大的节点为leader。即使出现同一时间，多个leader，也不影响paxos的正确性，只会增大并发写冲突的概率。 Raft算法 单点写入：任一时刻，只允许一个有效的leader存在，所有的写请求，都传到leader上，然后由leader同步给超过半数的follower。 单条日志结构：term + index + content。term是leader的任期，只会单调递增；index是日志顺序编号，也是递增； 分为三个阶段，选举阶段，正常阶段，恢复阶段 选举阶段 节点有三个状态：leader、follower、candidate。candidate是个中间状态。 当follower在一定时间收不到leader心跳时，就会随机sleep一个时间，然后变为candidate，发起选举。选举结束后，变为leader或follower。 选举算法，保证同一时间只有一个leader。 如果选举请求里，日志的term和index比自己本地的新，则返回true，否则返回false。 candidate收到多数派返回true，则成为leader 每个节点只能投一次true，防止多个leader。因此选取出的leader不一定是最新的，但一定比大多数节点新。 正常阶段，复制日志 只要超过半数的follower复制成功，就返回给客户端日志写入成功。 关键的日志一致性保证： 如果两个节点的日志，index和term相同，则内容一定相同。 如果index=M处的日志相同，则在M之前的日志，也一定相同。 恢复阶段 leader同步term给follower 以leader本地的日志为基准，复制给follower。这里比较特殊，如果新leader本身有未commit的日志，需要跟新的日志一起提交。避免一些特殊情况下，已commit的日志被覆盖。 安全性保证 leader数据是基准，leader不会从别的节点同步数据，只会是别的节点根据leader数据删除或追加自己的数据。 对于已经commit的日志，一定是commit的。对于新任leader上，前任leader未commit的日志，稍后会变为commit状态。不在新任leader上的未commit数据，会被覆盖。 Zabzookeeper使用的强一致性算法，同时也是单点写入，写请求都转发给leader。 模型对比，复制状态机(replicated state machine, paxos/raft) vs 主备系统（primay-backup system，zab）,前者持久化的是客户端的请求序列（日志序列），另外一个持久化的是数据的状态变化。 数据同步次数不一样，如果client执行三次x=1，后两次在主备系统里，不用触发同步。 存储状态变化，具有幂等性，而复制状态机不具备。 zxid 高32位，leader任期，类似raft的term 低32位，日志序列，类似raft的日志index 三个阶段：Leader选举，BroadCast,恢复阶段 Leader选举：FLE算法 Leader和Follower之间是双向心跳；raft里是单向 选取zxid最大的节点作为leader；和raft选取term+index最新的节点作为leader一个意思。 broadcast阶段 raft vs zab参考：https://my.oschina.net/pingpangkuangmo/blog/782702 上一轮残留的数据怎么处理？ 首先看下上一轮次的leader在挂或者失去leader位置之前，会有哪些数据？ 已过半复制的日志 未过半复制的日志一个日志是否被过半复制，是否被提交，这些信息是由leader才能知晓的， 那么下一个leader该如何来判定这些日志呢？ 下面分别来看看Raft和ZooKeeper的处理策略： Raft：对于之前term的过半或未过半复制的日志采取的是保守的策略，全部判定为未提交，只有当当前term的日志过半了，才会顺便将之前term的日志进行提交。 ZooKeeper：采取激进的策略，对于所有过半还是未过半的日志都判定为提交，都将其应用到状态机中 Raft的保守策略更多是因为Raft在leader选举完成之后，没有同步更新过程来保持和leader一致（在可以对外服务之前的这一同步过程）。而ZooKeeper是有该过程的","categories":[{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"系统原理","slug":"后端/系统原理","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"开天辟地","slug":"开天辟地","date":"2020-05-11T09:05:19.000Z","updated":"2020-05-14T03:04:18.669Z","comments":true,"path":"2020/05/11/开天辟地/","link":"","permalink":"http://yoursite.com/2020/05/11/%E5%BC%80%E5%A4%A9%E8%BE%9F%E5%9C%B0/","excerpt":"","text":"欢迎","categories":[],"tags":[]},{"title":"CSAPP-8.2-异常控制流2","slug":"CSAPP-8-2-异常控制流2","date":"2016-11-28T02:57:58.000Z","updated":"2016-11-28T02:57:58.000Z","comments":true,"path":"2016/11/28/CSAPP-8-2-异常控制流2/","link":"","permalink":"http://yoursite.com/2016/11/28/CSAPP-8-2-%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%812/","excerpt":"","text":"进程 进程是一个执行中的程序的实例。系统中的每个程序都是运行在某个进程的上下文中。上下文由程序正确运行所需的状态组成。这个状态包括，存放在存储器中的代码和数据，它的栈，通用目的寄存器内容，程序计数器，环境变量，以及打开文件描述符的集合。 每次用户向外壳（shell）运行一个可执行目标文件，shell会创建一个新的进程，然后再这个新进程的上下文中运行这个程序。应用程序也可以自己创建进程，并在创建的新进程中运行自己的代码或其他应用程序。 私有地址空间 进程为每个应用程序提供一个假象，好像它独占地使用系统地址空间。在一台有n位地址的机器上，地址空间是2n个可能地址的集合，0 ~ 2n-1。一般而言，和这个进程地址空间中的某个地址相关联的存储器字节，是不能被其他进程读写的。（肯定啊）从这个意义上说，这个地址空间是私有的。 地址空间的顶部（？~ 2n-1）是保留给内核的。这个部分包含内核的代码、数据、堆、栈等。 用户模式和内核模式 通过某个控制寄存器的一个模式位（mode bit），来控制进程运行在哪个模式。 运行应用程序代码的进程初始时是在用户模式中。进程从用户模式变为内核模式的唯一方法是通过中断、故障或者陷入陷阱进行系统调用。 Linux的/proc文件系统。它允许用户模式进程访问内核数据结构的内容。/proc文件系统将许多内核数据结构的内容输出为一个用户程序可以读的文本文件的层次结构。比如/proc/cpuinfo查看cpu类型，/proc//maps查看进程使用的存储器段。 上下文切换 发生时机 当程序切换到内核模式执行系统调用时，可能发生。如果系统调用因为某个等待的时间发生而阻塞，那么内核可以让当前进程休眠，切换到另一个进程。比如，一个read系统调用请求一个磁盘访问，内核可以选择执行上下文切换，运行另一个进程，而不是等待数据从磁盘到达。另一个示例是sleep系统调用，它显式的请求让调用进程休眠。 中断也可能引发上下文切换。每次发生定时器中断时，内核就判定当前进程已经运行了足够长的时间，并切换到一个新的进程。 中断处理程序/上下文切换 污染高速缓存中断处理程序如果访问了足够多的表项，那么再切换回应用程序时，缓存是冷的。上下文切换也会出现同样的情况。（那怎么办？） 系统调用错误处理当Unix系统级函数遇到错误时，它们会典型地返回-1，并设置全局整数变量errno来表示出了什么错。可以用strerror(errno)来返回errno此时相关联的错误。 进程控制进程ID 每个进程都有一个唯一的正数ID，称为PID。 可以用getpid()来获取。getppid()可以返回它父进程的PID。 创建、终止进程。 相同、独立的地址空间。父子进程拥有相同的用户栈、相同的本地变量值、相同的堆、相同的全局变量值、以及相同的代码。子进程得到与父进程用户级虚拟地址空间相同，但是独立的一份拷贝。包括文本、数据和bss段、堆以及用户栈。对比一下第七章讲的进程存储器映像，除下内核地址空间和共享库，其他都拷贝了。 子进程还获得和父进程任何打开的文件描述符相同的拷贝。这就意味着调用fork后，子进程可以读写fork之前父进程打开的任何文件。 阻塞，进程的执行被暂时挂起（suspend）。当收到SIGSTOP、SIGTSTP、SIGTTIN、SIGTTOU信号时，进程就会阻塞挂起，直到它收到一个SIGCONT信号才会继续。信号是一种软件中断的形式。 终止，进程永远停止。进程会因为三种原因终止： 收到一个信号，信号的默认行为是终止进程。（比如: kill -9） 从主程序（main）返回 调用exit函数。exit函数以status退出状态来终止进程（另一种设置退出状态的是从主程序返回一个数值） 回收子进程僵死进程 当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。相反，进程会保持在一种已终止的状态中，知道被它的父进程回收。当父进程回收已终止的子进程时，内核将子进程的退出状态（上一小节说的exit status？）传递给父进程，然后抛弃已终止的进程，从此时开始，该进程就不存在了。一个终止了，但还未被回收的进程称为僵死进程。 如果父进程没有回收它自己的僵死子进程就终止了，那么内核会安排init进程来回收它们。init进程PID为1，并且是由系统初始化时内核创建的。 等待子进程结束1231. waitpid(pid_t pid, int *status, int options)2. wait(int *status) ，相当于调用waitpid(-1, &amp;status, 0) 休眠123#include &lt;unistd.h&gt;unsigned int sleep(unsigned int secs); 如果请求的时间量到了，sleep返回0，否则返回还剩下的要休眠的秒数。后一种情况，可能发生在sleep函数被一个信号中断而提前返回的情况。 123#include &lt;unistd.h&gt;int pause(void); pause()函数使调用者休眠，直到该进程收到一个信号。 加载并运行程序，execve12#include &lt;unistd.h&gt;int execve(const char *filename, const char *argv[], const char *envp[]); execve函数加载并运行可执行文件filename，且带参数列表argv和环境变量列表envp。execve调用一次从不返回，除非出现错误。main函数也是三个参数，不过envp是隐藏的默认参数。 1int main(int argc, char *argv[], char *envp[]); 用户栈典型结构，注意啦，复习下进程的存储器映像，栈是从高地址向地地址分配，所以栈底的地址比栈顶大。argv和envp，都是以一个null元素结尾，因此即使不知道argv和envp的长度，也可以依次打印出来，而避免越界。 几个操作envp的函数 1234567#include &lt;stdlib.h&gt;char *getenv(const char *name);int setenv(const char *name, const char *newvalue, int overwrite);void unsetenv(const char *name); fork和execve区别fork函数在新的子进程中运行相同的程序，新的子进程时父进程的一个复制品。execve函数在当前进程的上下文中运行一个新的程序。它会覆盖当前进程的地址空间，但是并没有创建一个新进程。新的程序仍然有相同的PID，并且继承了调用execve函数时，已打开的所有文件描述符。 利用fork和execve运行程序shell进程就是这样来执行命令。简单版如下，再结合waitpid就可以实现相应的后台执行等功能。 12345678if（pid = fork() == 0)&#123; if(execve(argv[0], argv, environ) &lt; 0) &#123; printf(\"%s: Command not found.\\n\", argv[0]); exit(0); &#125;&#125;","categories":[{"name":"系统原理","slug":"系统原理","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"CSAPP","slug":"系统原理/CSAPP","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/CSAPP/"}],"tags":[{"name":"CSAPP","slug":"CSAPP","permalink":"http://yoursite.com/tags/CSAPP/"}]},{"title":"CSAPP-8.3-异常控制流3","slug":"CSAPP-8-3-异常控制流3","date":"2016-11-28T02:57:58.000Z","updated":"2016-11-28T02:57:58.000Z","comments":true,"path":"2016/11/28/CSAPP-8-3-异常控制流3/","link":"","permalink":"http://yoursite.com/2016/11/28/CSAPP-8-3-%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%813/","excerpt":"","text":"信号简介 每种信号类型都对应某种系统事件。底层的硬件异常是由内核异常处理程序处理的，正常情况下，堆用户进程而言是不可见的。信号提供了一种机制，统治用户进程发生了这些异常。当一个子进程终止或者停止时，内核会发送一个SIGCHLD信号给父进程。 发送信号 内核更新目的进程上下文中的某个状态，来给目的进程发送信号。一个进程可以给它自己发信号。向进程发信号都是基于进程组（process group）的概念。 进程组。每个进程都只属于一个进程组，进程组由一个正整数进程组ID, pgid标识。shell也为每个作业（job）都创建一个独立的进程组，pgid是新进程的pid。如果这个新进程再继续创建子进程，默认地，一个子进程和它的父进程同属于一个进程组。一个进程可以通过函数改变自己活其他进程的进程组。（权限？） 12345#include &lt;unistd.h&gt;pid_t getpgrp(void); //返回调用进程的进程组IDint setpgid(pid_t pid, pit_t pgid); //设置一个进程的进程组id，成功返回0，失败-1. kill命令可以给其他进程发送任意的信号。 123kill -9 1234 //给进程1234发送信号9（SIGKILL）kill -9 -1234 //负的pid，表示给1234这个进程组，的每个进程发信号9kill -9 0 //0，给当前进程所在进程组，的每个进程发信号9 12345#include &lt;sys/types.h&gt;#include &lt;signal.h&gt;/* 进程可以调用kill函数发送信号，包括给他们自己 */int kill(pid_t pid, int sig); 1234#include &lt;unistd.h&gt;/* 调用alarm函数可以给它自己发送SIGALRM信号 */unsigned int alarm(unsigned int sig); 接收信号 接收信号。内核为每个进程在pending位向量维护着待处理信号的集合，而在blocked位向量中维护着被阻塞的信号集合。所以在任何时刻一种类型的信号只会被接收一次，在处理它的时候，会先把该类型的信号block。进程可以忽略信号，也可以捕获这个信号，执行信号处理程序。 当内核从一个异常处理程序返回（进程调度也属于一种异常？定时器中断？），准备把控制传递给某个进程p时，它会检查进程p的未被阻塞的待处理信号集合（pending &amp; ~blocked）。如果这个集合不为空，那么内核选择集合中的某个信号k（通常是编号最小的信号，所以Linux信号编号还是特意的呢，编号越小，优先级越高），并进入k的处理程序。 Ps:在block的时候，来的信号会不会标记到pending里？ 答案：会的。执行信号的处理动作称为信号递达（Delivery），信号从产生到递达之间的状态，称为信号未决（Pending）。进程可以选择阻塞（Block）某个信号。被阻塞的信号在产生时将保持在未决状态，直到进程解除对此信号的阻塞，才执行递达的动作。注意，阻塞和忽略是不同的，只要信号被阻塞就不会递达，而忽略是在递达之后可选的一种处理动作。忽略也可以说是信号处理程序的一种。 信号的默认处理程序是如下中的一种： 进程终止 进程终止并转储存储器（dump core） 进程暂停，直到被SIGCONT信号重启 进程忽略该信号 修改信号的默认处理程序（忽略，恢复默认行为，自定义） 12345#include &lt;signal.h&gt;typedef void (*sighandler_t)(int);sighandler_t signal(int signum, sighandler_t handler); 待处理信号被阻塞。Unix信号处理程序通常会阻塞当前处理程序正在处理的类型的信号。比如正在执行SIGINT处理程序时，如果再来一个SIGINT信号，只会在pending里置1（感觉此时应该已经为1了）。 系统调用可以被中断。像read、wait和accept这样的系统调用会潜在地阻塞进程一段时间，称为慢速系统调用。在某些操作系统中，若正在执行慢速系统调用的时候收到了信号，当从信号处理程序返回时，原来的慢速系统调用可能不会继续，然而由于被信号中断，系统调用的任务并未完成。Linux系统会自动重启被中断的系统调用。 阻塞和取消阻塞信号 1234567891011121314151617#include &lt;signal.h&gt;/* 改变blocked向量的值，若oldset!=null，会用来保存以前blocked向量的值 */int sigprocmask(int how, const sigset_t *set, sigset_t *oldset);/* 初始化set为空集 */int sigemptyset(sigset_t *set);/* 初始化set全为1，每个信号都填入blocked向量 */int sigfillset(sigset *set);/* 添加、删除signum到set */int sigaddset(sigset_t *set, int signum);int sigdelset(sigset_t *set, int signum);/* set中对应signum是否置1 */int sigismember(const sigset_t *set, int signum); 非本地跳转C语言提供了一种用户级异常控制流形式，称为非本地跳转（nonlocal jump)。它将控制直接从一个函数转移到另一个当前正在执行的函数，而不需要经过正常的调用-返回序列。涉及到的两个函数分别是setjmp和longjmp。 1234567#include &lt;setjmp.h&gt;int setjmp(jmp_buf env);int sigsetjmp(sigjmp_buf env, int savesigs);void longjmp(jmp_buf env, int retval);void siglongjmp(sigjmp_buf env, int retval); setjmp函数在env缓冲区中保存当前的调用环境，以供后面longjmp使用，并返回0，调用环境包括程序计数器、栈指针和通用目的寄存器。 longjmp函数从env缓冲区中恢复调用环境，然后从最近一次setjmp的env中恢复，恢复的时候相当于setjmp函数的返回，只是返回值非0（longjmp的第二个参数）。longjmp函数只有调用，没有返回。此外，setjmp函数调用一次，可以返回多次。 非本地跳转的一个重要应用是允许从一个深层嵌套的函数调用中立即返回。如果再一个深层嵌套的函数中发现了错误，可以调用longjmp(env, ret)，直接返回到setjmp处，然后根据返回的ret值判断是什么错误，调用什么样的错误处理程序。类似java的try…catch语句。 操作进程的工具 strace: 打印一个正在运行的程序和它的子进程调用的每个系统调用的轨迹。 pmap: 显示进程的存储器映射 /proc：一个虚拟文件系统，以ASCII文本格式输出大量内核数据结构的内容，用户程序可以读取这些内容。比如 cat /proc/loadavg，观察linux系统上当前的平均负载。","categories":[{"name":"系统原理","slug":"系统原理","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"CSAPP","slug":"系统原理/CSAPP","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/CSAPP/"}],"tags":[{"name":"CSAPP","slug":"CSAPP","permalink":"http://yoursite.com/tags/CSAPP/"}]},{"title":"CSAPP-8.1-异常控制流1","slug":"CSAPP-8-1-异常控制流1","date":"2016-11-28T02:50:57.000Z","updated":"2016-11-28T02:50:57.000Z","comments":true,"path":"2016/11/28/CSAPP-8-1-异常控制流1/","link":"","permalink":"http://yoursite.com/2016/11/28/CSAPP-8-1-%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%811/","excerpt":"","text":"前言这一章真是解惑众多啊，关于中断、信号、进程。非常非常值得一看，CSAPP真是神书。 异常定义和场景 现代系统通过使控制流发生突变来对这些情况做出反应。异常发生在计算机系统的各个层次，比如： 硬件层，硬件检测到的事件会出发控制突然转移到异常处理程序。 操作系统层，内核通过上下文转换将控制从一个用户进程转移到另一个用户进程。 应用层，一个进程可以发送信号到另一个进程，信号接收者会将控制突然转移到它的一个信号处理程序。 应用程序通过陷阱（trap）或者系统调用（system call）的ECF形式，向操作系统请求服务。 异常的执行异常处理程序在执行结束后，会发生以下三种情况之一： 返回应用程序当前指令Icurr 返回应用程序的下一条指令Inext 异常处理程序终止被中断的应用程序 异常的处理基本知识 系统中的美中类型异常都分配了一个唯一的非负整数，作为异常号。系统启动时会初始化一张异常表，异常表的起始地址存在一个特殊的CPU寄存器里，异常表基址寄存器。 异常处理程序运行在内核模式，这意味着它们对所有的系统资源都有完全的访问权限。 异常分类：中断是异步的，不由任何一条指令造成。其他三种异常是同步的，是执行当前指令的结果。 中断 来自处理器外部I/O设备的信号的结果。硬件中断不是由任何一条专门的指令造成的。I/O设备通过向处理器芯片上的一个引脚发信号，并将异常号放到系统总线上，以触发中断，这个异常号标识了引起中断的设备。（也有软件中断？比如信号？） 中断处理的重点： 检测到引脚电压变高，当前的指令会继续执行结束 返回下一条指令 陷阱和系统调用 陷阱是有意的异常，是执行一条指令的结果。最重要的用途是在用户程序和内核之间提供一个接口，称为系统调用。 从程序员角度，系统调用和普通函数调用是一样的，然而它们的实现不同。普通函数运行在用户模式，用户模式限制了函数可以执行的指令类型，而且它们只能访问与调用函数相同的栈。系统调用运行在内核模式，内核模式允许系统调用执行指令，并访问定义在内核中的栈。 陷阱处理的重点: 程序员主动调用，比如syscall指令。 返回下一条指令，上一条指令就是syscall。 故障 故障时由于指令执行发生了错误。这个错误可能被修复，若处理程序修复了，则返回重新执行这条指令，否则返回到内核中的abort例程（当做内核对外提供的一个服务即可），abort例程会终止引起该故障的应用程序。 一个经典的故障是缺页异常，当指令引用一个虚拟地址，而该虚拟地址相对应的物理页面不在存储器（包含缓存，主存等）中，因此必须从磁盘中取时，就会发生故障。当缺页处理程序加载好后，就将控制返回给应用程序。此时原指令再次执行，由于相应页面已经被加载到存储器中，因此此次执行不会引起故障。 故障处理的重点 指令执行的结果。 故障恢复成功。返回当前指令，重新执行一次。（会不会出现死循环？） 故障恢复失败。通过abort例程，终止程序。 终止 终止时由于不可恢复的致命错误造成的结果。通常是一些硬件错误。终止处理程序直接将控制返回给abort例程，abort例程去终止这个应用程序。 终止处理的重点 执行指令时，发生了不可恢复的致命错误。 应用程序会直接终止。 Linux/IA32中的异常异常 有256种异常类型。031号为Intel架构师定义，32255由操作系统定义的中断或陷阱。举例： 特别出名的，比如“段错误”对应的是13，一般保护故障，通常是由于程序引用了一个未定义的虚拟存储器区域。系统调用是0X80. Linux/IA32系统调用 系统调用是异常的一种，属于陷阱，有意的异常。 IA32系统上，系统调用通过一条称为int n的陷阱指令来提供。Linux提供上百种系统调用。每个系统调用都有一个唯一的整数号，对应于一个到内核中跳转表的偏移量。看图：C语言用syscall函数可以直接调用任何系统调用。然而实际中没必要这么做，标准C库做了很多封装的工作，使用更方便。所有到Linux系统调用的参数都是通过通用寄存器，而不是栈来传递的。","categories":[{"name":"系统原理","slug":"系统原理","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"CSAPP","slug":"系统原理/CSAPP","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/CSAPP/"}],"tags":[{"name":"CSAPP","slug":"CSAPP","permalink":"http://yoursite.com/tags/CSAPP/"}]},{"title":"CSAPP-7-链接","slug":"CSAPP-7-链接","date":"2016-11-16T03:53:49.000Z","updated":"2016-11-16T03:53:49.000Z","comments":true,"path":"2016/11/16/CSAPP-7-链接/","link":"","permalink":"http://yoursite.com/2016/11/16/CSAPP-7-%E9%93%BE%E6%8E%A5/","excerpt":"","text":"前言这章有点细，得慢慢读，有的地方名词稍微有点不同，很容易看错。不得不说CSAPP是本好书，如果要想更加深入，还是去读原书吧，然后做些实验。 从代码到可执行文件（gcc为例，gcc main.c -o test） 预处理器(cpp)将源程序翻译成一个ASCII码的中间文件 main.i C编译器(cll)将main.i翻译成一个ASCII汇编语言文件 main.s 汇编器(as)将main.s翻译成一个可重定位目标文件，main.o 链接器(ld)将多个.o文件以及一些必要的系统目标文件组合起来，创建一个可执行目标文件 链接必须完成两个主要任务： 符号解析目标文件定义和引用符号。符号解析的目的是将每个符号引用刚好和一个符号定义联系起来。（这里的符号包括变量名和函数名） 重定位链接器通过把每个符号定义和一个存储器位置联系起来，然后修改所有对这些符号的引用，使得它们指向这个存储器位置，从而重定位这些节。（联想程序实际执行时是通过移动PC来执行存储器中某一地址的指令。“节”是可重定位目标文件的构造协议而言） 目标文件（Executable and Linkable Format, ELF）三种ELF文件形式： 可重定位目标文件包含二进制代码和数据，其可以在编译时与其他可重定位目标文件合并起来，组成一个可执行二进制文件。 可执行目标文件包含二进制代码和数据，可以被直接拷贝到存储器中执行。 共享目标文件特殊类型的可重定位目标文件，可以在加载或运行时被动态地加载到存储器，并链接。 可重定位目标文件文件结构下图是一个典型的ELF文件格式。 ELF头，以一个16字节的序列开始，描述生成该文件的系统的字的大小和字节顺序。剩下字节包括帮助链接器语法分析和解释目标文件的信息，包括ELF头的大小、目标文件的类型（可重定位、可执行、共享的）、机器类型（如IA32）、节头部表的文件偏移，以及节头部表（见图最后）中的条目大小和数量。夹在ELF和节头部表中间的都是节。 .text，已编译的机器代码。 .rodata，read only data，只读数据，比如printf语句中的格式串和switch的跳转表。 .data，已初始化的全局C变量。局部变量在运行时保存在栈中，既不在.data，也不在.bss中。 .bss，未初始化的全局C变量。这个节不占据实际的磁盘空间。区分初始化和未初始化是为了空间效率。（意思是，.data磁盘实际保存的只有初始化的全局变量） .symtab，符号表，程序中定义和引用的函数和全局变量的信息。每个ELF文件都有。 .rel.text，当链接噐把这个目标文件和其他文件结合时，.text节中的许多位置都需要修改。一般而言，任何调用外部函数或者引用全局变量的指令都需要修改。另一方面调用本地函数的指令则不需要修改。然而可执行目标文件中并不需要重定位信息，除非用户指定。 .rel.data，被模块引用或定义的任何全局变量的重定位信息。一般而言，任何已被初始化的全局变量，如果它的初始值是一个全局变量地址或者外部定义函数的地址（指针？），都需要被修改。 .debug，调试符号表。条目是程序中定义的局部变量和类型定义，定义和引用的全局变量，原始的C源文件。-g选项编译才会得到这张表，gdb调试？ .line，原始C源程序行号和.text节机器指令之间的映射关系。要求-g编译。 .strtab，一个字符串表，每个字符串以null结尾。包括.symtab和.debug中的符号表，节头部中的节名字。 符号和符号表每个可重定位目标模块m都有一个符号表(.symtab) 由m定义并能被其他模块引用的全局符号。对应：非静态的C函数以及非静态的C全局变量。 只被m定义和引用的本地符号。对应：带static的C函数和static全局变量。以及static局部变量。 由其他模块定义，并被m引用的全局符号，称为外部符号。对应：定义在其他模块中的C函数和变量。 PS:在函数内部定义的static变量，不在栈中管理。而是在.data和.bss中为每个定义分配空间，并且在.symtab中创建一个名字唯一的本地符号。 符号解析符号解析是链接的两个主要任务之一，方法是将每个引用和一个确切的定义联系起来。那么如果多个目标文件同时定义了相同的符号怎么办哩？ 强、弱符号强符号：函数和已初始化的全局变量。弱符号：未初始化的全局变量。 Unix链接器使用如下规则来处理多重定义的符号： 不允许有多个强符号 一个强符号，多个弱符号，选强符号 只有多个弱符号，随便选一个（卧槽，这种不确定性看起来就好坑啊） 举个例子说明链接器对规则2和规则3相关的错误 12345678910/* main.c */#include &lt;stdio.h&gt;void func();int x = 1;int y = 2;int main()&#123; func(); printf(\"x = %x, y = %x\\n\", x, y);&#125; 1234567/* func.c */double x;void func()&#123; x = -0.0;&#125;// output: x = 0, y = 8000 0000 这种情况，在生成可重定位的模块时文件时，都不会有错误。在链接的时候这也不会报错。double是8个字节（32w位上也是8字节，只有整数有区别），而int是4个字节，因此在func()中对x的赋值会覆盖x,y的位置，因此y的内存表示就变为了00 00 00 80，又由于机器是小端的，所以y=8000 0000.当然也是有解决办法的，编译时通过使用以下参数，在遇到多重定义的全局符号时，会输出警告信息。 1gcc -fno-common main.c func.c -o t 静态库静态库概念在Unix系统中，静态库以存档（archive，*.a）的特殊文件格式存放在硬盘上。 12gcc -c func1.c func2ar rcs libfunc.a func1.o func2.o 此外，链接的时候，拷贝到最终可执行文件的基本单位还是模块。比如只用到了func1.o，就不会同时打包libfunc.a里面的func2.o 静态库链接过程 链接器按照命令行输入顺序，从左到右扫描可重定位目标文件和存档文件（静态库）。 在此次扫描中，链接器维持一个可重定位目标文件的集合E（这个集合的文件会被合并起来形成可执行文件），一个未解析符号集合U（引用了但是尚未定义），以及一个已定义符号集合D（前面输入文件已定义）。刚开始E、U、D都是空的。 > 1. 对于命令行的每个输入文件f，先判断f是目标文件还是存档文件。目标文件直接把f加入E，然后根据f的内容修改U,D集合。 > 2. 若f是存档文件，尝试匹配U中未解析的符号。如果某个存档文件成员m，定义了一个符号来解析U中的一个引用，那么就将m加入E中，并且根据m的内容来修改U,D集合。对存档文件的所有成员反复进行这个过程，直到U，D不再发生变化。然后继续处理下一个文件。 > 3. 如果链接器完成了对所有输入文件的扫描后，U是非空的，那么链接器就会输出一个错误并终止。若U为空，则表明各个符号解析成功，它会合并和重定位E中的目标文件，输出可执行目标文件。 所以，一般将库放在命令行的结尾。若是有特殊的需求，比如循环引用，也可以在命令行上重复导入某个库。（出现这种情况，更好的办法应该是，这两个相互依赖的模块放在同一个.a存档文件中）。 重定位重定位是链接的第二个任务，将符号定义与一个特定的存储地址联系起来。 重定位由两步组成 重定位节和符号定义这一步链接器将所有相同类型的节合并为同一类型的新的聚合节。例如来自输入模块的.data节全部被合并成一个节，这个节成为输出的可执行目标文件中的.data节。这一步完成时，程序中的每一个指令和全局变量都有唯一的运行时存储器地址了。（指令在.txt，全局变量在.data，当所有节的大小都确定后，相对地址也就确定了。这么理解？） 重定位节中的符号引用链接器修改代码节和数据节中对每个符号的引用，使它们指向正确的运行时地址。这一步依赖于代码和数据的重定位条目。.rel.text和.rel.data节。前者存放代码的重定位条目，后者存放已初始化数据的重定位条目。重定位PC相对引用、重定位绝对引用这两种绝对和相对都是相对来说的。即使是绝对引用，也是相对于链接第一步合并后的文件来说的。 可执行目标文件下图是一个典型的ELF可执行目标文件结构对比一下实际运行时的存储器映像 可执行目标文件ELF头部描述文件的总体格式。它还包括程序的入口点，也就是程序运行时第一条执行的指令地址。.text、.rodata、.data节和之前的可重定位目标文件中的对应节类似，只是它们已经被重定位到最终的运行时存储器地址。.init节定义了一个小函数_init，程序的初始化代码会调用它。由于可执行文件时完全链接（重定位过），因此不再需要.rel.text和.rel.data节。 加载可执行目标文件 Unix的shell通过调用execve函数来调用加载器（loader），加载器将可执行文件的代码和数据（精确，不包括其他段）从硬盘拷贝到存储器中，然后跳转到其第一条指令开始运行。 Linux将这个运行时存储器映像组织成若干段的集合，它主要有两部分：进程虚拟存储器、内核虚拟存储器。进程虚拟存储器有我们熟悉的代码段、数据段、运行时堆、共享库段、用户栈。内核虚拟存储器包括内核中的代码和数据结构、与进程相关的数据结构。以32位系统的可执行文件的运行时存储器映像来说： 代码段总是从地址0x08048000处开始，它保存编译程序的机器代码 data段在接下来的一个4KB对齐的地址处，保存已初始化的全局C变量和静态变量 bss段记录的是未初始化的全局C变量，事实上它并不占据目标文件的任何空间，只是一个占位符 运行时堆在接下来的第一个4KB对齐的地址处，通过调用malloc库向上增长，用于程序的动态内存管理 共享库段，用于加载共享库、映射共享内存和文件I/O,使用mmap和unmap函数申请和释放新的内存区 用户栈占据进程地址空间的最高部分，并向下增长，用于存放调用过程中的局部变量、函数返回地址、参数 内核代码和数据、物理存储器，它们均被映射到所有进程共享的物理页面，这就为内核提供一个便利的方法来访问内存中任何特定的位置。对于每个进程来说他们均是一样的 最顶层的内核地址空间包括了与进程有关的数据结构，如页表、内核在进程的上下文结构task_struct和mm结构，内核栈 存储器映像创建好后，加载器跳转到程序的入口点，也就是符号_start的地址。_start在目标文件ctrl.o中定义。然后执行所有C/C++都需要的startup/exit流程:（call __libc_init_first =&gt; _init =&gt; atexit =&gt; main =&gt; _exit）。 动态链接共享库 即使使用静态库，加载时也会出现重复加载到存储器的浪费情况，比如C标准库。 共享库（shared library）也称共享目标（shared object），Unix中，通常用.so后缀表示。（静态库是.a）。Windows中用.dll文件表示（dynamic linking library）。 给定的文件系统中，对于一个库只能有一个.so文件；其次，在存储器中，一个共享库的.text节的一个副本可以被不同的运行进程共享。 链接时，不会有任何.so的代码和数据节被拷贝到可执行目标文件中，只拷贝了一些重定位和符号表信息，以便于运行时可以解析对.so中的代码和符号引用。 对共享库的引用有两种，一是在程序执行之前，被加载时，动态加载器加载和链接共享库；二是，在运行时通过动态加载器加载、链接特定的库，而无需再编译时链接那些库到应用中（有点像Java的动态加载Class.forName(…)）。 运行时加载的相关API：12345678910111213#include &lt;dlfcn.h&gt;/* 打开共享库，成功返回指向句柄的指针，失败返回null */void *dlopen(const char *filename, int flag);/* 解析符号，输入是共享库句柄指针和符号名，成功返回符号地址，失败返回null */void *dlsym(void *handle, char *symbol);/* 卸载共享库，如果此时没有其他共享库正在使用这个共享库的话 */int dlclose(void *handle)/* 返回上面三个api发生的错误，需要手动调用，没有错误返回null */const char *dlerror(void)","categories":[{"name":"系统原理","slug":"系统原理","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"CSAPP","slug":"系统原理/CSAPP","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/CSAPP/"}],"tags":[{"name":"CSAPP","slug":"CSAPP","permalink":"http://yoursite.com/tags/CSAPP/"}]},{"title":"CSAPP-6-存储器的层次结构","slug":"CSAPP-6-存储器的层次结构","date":"2016-11-07T12:56:22.000Z","updated":"2016-11-07T12:56:22.000Z","comments":true,"path":"2016/11/07/CSAPP-6-存储器的层次结构/","link":"","permalink":"http://yoursite.com/2016/11/07/CSAPP-6-%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/","excerpt":"","text":"前戏：关于读书顺序能够顺着读下来当然是很好的，但是呢，一方面可能读着读着感觉无趣乏味，另一方面可能书的本身书写顺序就不是很好。所以，在前后因果关系不大的情况下，完全可以跳着读，挑感兴趣或简单的读，没问题。 关键点 时间局部性、空间局部性 缓存的大概原理 机械硬盘的设计、访问开销。 存储器山 存储技术 随机访问存储器（RAM, Random-Access Memory) SRAM，静态，双稳态 DRAM，动态，敏感，存储器系统需要周期性地读写刷新存储器的每一位。 DRAM阵列 DRAM组成二维阵列而不是一维线性数组的一个原因是降低芯片上地址引脚的数量。例如，16个超单元组成的阵列，二维和一维分别需要2个和4个地址引脚。二维组织的缺点是，地址必须分两步发送，增加了访问时间。（一个行地址，一个列地址）。 再加一个存储控制器和缓存行，收到行地址，读取整行放入缓存行，之后收到列地址，返回某一个超单元的数据。 访问主存还记得这张老图吗？系统总线是一组并行的导线，能携带地址、数据和控制信号。但是不同总线不能直接互通，这就用到了I/O桥。Intel系统： 北桥：系统总线 &lt;=&gt; 存储器总线，连接主存 南桥：系统总线 &lt;=&gt; I/O总线，连接I/O设备 旋转磁盘 构造 盘片（表面） 磁道，表面上的一组同心圆 扇区，每个磁道被划分为一组扇区，每个扇区包含相同量的数据位(通常是512byte)。扇区之间由一些间隙分隔开，间隙中不存储数据位，同时用来标识扇区的格式化位。柱面，所有盘片表面上到主轴中心距离相等的磁道集合。（不同表面上半径相同的磁道）读写头，任何时刻，不同表面的磁头都位于同一个柱面上。如图: 多区记录技术。原本为了保持每个磁道有固定的扇区数，越往外的磁道扇区隔得越开。多区记录技术把柱面分为多个不相交的子集合，称为记录区。每个区包含一组连续的柱面。同一个区中的磁道上扇区的数量是相同的，这个数量由该区中最里面的磁道所能包含的扇区数决定。 容量计算 访问时间（access time）对扇区的访问时间主要分为三个部分： 寻道时间：将磁头定位到目标扇区所在的磁道。这个时间依赖于磁头之前的位置和传动臂在盘面上移动的速度。通常3~9ms。 旋转时间：找到目标所在的第一个扇区。性能依赖于当前到达的磁道上相对目标扇区的位置和磁盘的旋转速度。 传送时间：读写扇区内容的时间。依赖于旋转速度和当前磁道的扇区数目。 实际中，主要是寻道时间和旋转时间。传送时间大概要小2~3个数量级。 磁盘控制器磁盘控制器，维护着逻辑块号（0, 1…B-1）和实际物理磁盘扇区之间的映射关系，翻译地址。（盘面，磁道，扇区）的三元组唯一标识了对应的物理扇区。 存储器映射I/OCPU使用存储器映射I/O（memory-mapped I/O）的技术来向I/O设备发出命令。在使用存储器映射I/O的系统中，地址空间有一块是为与I/O设备通信保留的。每个这样的地址称为I/O端口。当一个设备连接到总线时，它与一个或多个端口相关联。 直接存储器访问技术（Direct Memory Access，DMA）由于磁盘太慢，比如旋转磁盘访问时间都在毫秒级别。比如1GHz的处理器时钟周期是1ns，1ms可以执行100万条指令。所以，在读磁盘数据的时候，如果什么都不做是一种极大的浪费。DMA技术： 在磁盘控制器收到来自CPU的命令后，它将逻辑块号翻译成一个扇区地址，读该扇区的内容后，将这些数据直接传送到内存，不需要CPU的干涉。设备可以自己执行读或写总线事务，这个过程称为DMA。 DMA传送完成后，磁盘控制器给CPU发送一个中断信号来通知CPU。 局部性 时间局部性：重复引用同一个变量的程序有良好的时间局部性。 空间局部性：对于具有步长为k的引用模式的程序，步长越小，空间局部性越好。 循环，循环本身在CPU里的运行效率是比一般的非循环指令要高的，但是由于一段程序里，循环部分占用的绝对值时间比较大，因此给人一种错觉就是，循环比较慢，这是两个不同的角度。 高速缓存器 基本构造（S, E, B, m）,m是地址w的位长度。 S，S=2^s个组。 E，每组E个高速缓存行。 B，每个缓存行作为一个数据块，有B=2^b个字节。地址w的最后b位是块偏移。设计得真是巧啊，配合组号，正好可以把一段连续内存地存放在连续的缓存块里。 1位有效位，指明该行是否有效。 t位标记位，t=m-b-s。唯一标识一个缓存行（数据块) 容量计算：高速缓存确定一个请求是否命中，然后取出被请求的字的过程，分为三步：1）组选择，2）行匹配，3）字抽取。当且仅当设置了有效位，而且标记位与w地址中的标记位相匹配时才算命中。 分类 直接映射高速缓存，每个组只有一行。 组相联高速缓存，每个组不止一行。 全相联高速缓存，只有一个组，所有的缓存行都在一个组里。 高速缓存的写 缓存命中 直写。立即将w的高速缓存块写到低一层的存储器中。缺点是每次写都会引起总线流量。通常是非写分配的形式。 写回。尽可能的推迟存储器更新，只有当替换算法要驱逐已经更新过的块时，才把它写到低一层的存储器里。优点是，写回能显著地减少总线流量。缺点是，它增加了缓存的复杂性，每个缓存行必须维护一个额外的修改位（dirty bit），标明该行是否被修改过。通常是写分配的形式。 不命中 写分配，加载低一层的块到高速缓存中，然后更新这个高速缓存块。写分配视图利用写操作的空间局部性（下一次写操作可能是下一个地址的内容）。缺点是：每次写不命中都会导致一个块从低一层传送到高速缓存。 非写分配，避开高速缓存，直接把这个字写到低一层中。 其实就两种情况，写到低一层存储器的时候，是否要经过高速缓存。 计算缓存的不命中率 最根本的原理是根据缓存的参数，计算出来地址里各个部分分别占几位，然后就每次访问的地址进行计算，观察是否在缓存中。 简单点的，S、E、B其实是特别巧的，低b位就是块偏移，然后是s位的组号。同一组的数据都有相同的组号。算下来，内存中的每一块会按顺序正好填充到缓存中。所以只需要看缓存是否能够存下这整块数据，若能，就只有第一次访问的时候会存在冷不命中，此时，不命中率=组数/访问数。若不能，则看情况了，尤其是访问步长不为1的时候。 存储器山 的概念读速度是时间和空间局部性的二维函数。时间局部性的表现一是可以通过程序优化，二是可以加大内存，目的是使得一段程序的运行数据全部都在缓存里命中。","categories":[{"name":"系统原理","slug":"系统原理","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"CSAPP","slug":"系统原理/CSAPP","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/CSAPP/"}],"tags":[{"name":"CSAPP","slug":"CSAPP","permalink":"http://yoursite.com/tags/CSAPP/"}]},{"title":"CSAPP-2-信息的表示和处理","slug":"CSAPP-2-信息的表示和处理","date":"2016-10-30T13:48:57.000Z","updated":"2016-10-30T13:48:57.000Z","comments":true,"path":"2016/10/30/CSAPP-2-信息的表示和处理/","link":"","permalink":"http://yoursite.com/2016/10/30/CSAPP-2-%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86/","excerpt":"","text":"信息的表示和处理开篇对计算机底层数的位形式表示和运算有疑问的同学，非常推荐一读。各种细节问题，拨云见日，豁然开朗。 信息存储 数字表示，分三种情况： 无符号整数，普通二进制形式 有符号整数，补码。 浮点数，IEEE 754标准。 最小可寻址存储器单位：字节（byte），8个二进制位（bit），2个16进制字符表示。 16进制记忆小技巧，记住A-10， C-12，F-15就可以了。 字长计算机的字长表示的是，处理器一次能够处理的最长二进制位数。当然也依赖操作系统和编译器。但是编译器程序的整数字节数，比如int、long的最大长度，跟计算机字长无关。比如java不分32位、64位，所有的long都是8个字节，64位。这种想法主要源于，32位机器上C语言的long是4byte，64位机器上是8byte。坑啊。。 字节序：大端、小端。前提：计算机读取主存的顺序是从低位到高位。莫忘，基本单位是字节大端：如同人阅读顺序。千位在低位内存，个位在高位内存。小端：intel处理器，和大端正好相反。 以数字 0x123456为例。随着内存地址递增的顺序： 大端：0x12 0x34 0x56 小端：0x56 0x34 0x12 字节是基本的存储和读取单位！！它的值是不变的,所以字节内部顺序是不变的。 整数的三种表示方式：原码、反码、补码，这三种方式可以互相通过一定的运算转换，但是它们都是独立的表示方式，都可以独立地表示正、负整数。 原码：最高位有效位，剩下的位决定值。这种表示方式最好理解。 反码：最高位的权是，，其他跟补码是一样的。 补码，现在计算机里大多用的就是补码，原因是加减操作可以使用统一的位操作。计算时，最高位的权为。补码可以从原码转换过来，正数的补码表示跟其原码表示相同，负数的补码是原码的按位取反再加一。 此外，负数的补码往前扩充1值是不变的，如0xFF表示-1，0xFFFF还是-1，注意二进制轴上的对应关系。 一个w位的有符号数（补码）表达范围。w位无符号数表达范围。注意在位的角度它们的对应关系，比如32位补码-1的16进制表示为【0xFFFFFFFF】 C语言printf在输出的时候，%u-无符号整数，%d有符号整数，根据格式化指示符来解释入参的“二进制位”。还要注意如果要输出一个byte的二进制要用unsigned char *指针，char *指针会由于位扩展，输出扩展后的4个字节，根据原字节首位的情况，正数前面扩展0，负数扩展1。 整数的加减法运算 前提：在CPU看来，所有的数的二进制表示都是补码。所有的操作都是位上的操作。所有的溢出，高位都被直接截断丢掉。至于某一串二进制如何解释（有or无符号），这是人为的设定。 结论：减去一个二进制串，等于加上其逆元。 逆元 = 二进制按位取反再+1。(是不是和原码转补码很像？但是切记，不是一个东西。)减法运算，有符号整数无需多言，减去一个数等于加上该数的逆元。有符号整数也是如此，举例为证。 1234//假设int是8位 unsigned int a = 1; //0b0000 0001 unsigned int b = 2; //0b0000 0010 printf(\"%s\\n\", a-b&gt;0?\"true\":\"false\"); //output:true 解释一下a-b的过程，先求b的逆元 0b1111 1110，与a相加，结果0b1111 1111，按补码解释也就是-1，按无符号整数解释是255，所以输出true。那么如何判断加法运算是否溢出？画个二进制轴，特别好理解。 12345678910111213141516// 无符号加法int uadd_ok(unsigned x, unsigned y)&#123; unsigned sum = x + y; return sum &gt;= x;&#125;// 有符号，分情况，正溢出or负溢出int tadd_ok(int x, int y)&#123; int sum = x + y; int neg_over = x &lt; 0 &amp;&amp; y &lt; 0 &amp;&amp; sum &gt; 0; int pos_over = x &gt;= 0 &amp;&amp; y &gt;= 0 &amp;&amp; sum &lt; 0; return neg_over || pos_over;&#125; 整数乘法同样，有符号与无符号在CPU看来，都是两个二进制串的同一个操作。对于乘法有可能溢出的情况，同样，保留后w位，截断高位。乘法通常都比较慢，需要10个时钟周期或更多。然而其他整数运算（例如加法、减法、位级运算和移位）只需要一个时钟周期。因此乘以一个常数，可以考虑用移位代替。即使乘法发生了溢出，也是有效的。如: 123x * 14; 相当于 (x&lt;&lt;3) + (x&lt;&lt;2) + (x&lt;&lt;1); &#x2F;&#x2F; 三个移位，两个加法 也相当于 (x&lt;&lt;4) - (x&lt;&lt;1); &#x2F;&#x2F; 两个移位，一个加法。 整数除法大多数机器上，整数除法比整数乘法更慢—需要30个或更多时钟周期。总是向零舍入。-3/2=-1; 3/2=1;除数如果是2的正数幂，可以通过右移位来实现，但是无法推广到普通的除数。其实是个分配律的问题x * (a + b + c) = x * a + x * b + x * c; 然而 x / (a + b + c)不行。 浮点数直接说IEEE 754标准的浮点数表示。一个二进制串分为三部分。 符号位，1位，决定正负。 阶码 E，对浮点数加权，2^E。C语言里float，8位；double, 11位。 尾数 M，二进制小数，计算分情况。C里float, 23位；double, 52位。 计算根据阶码分为三种，规格化、非规格化、特殊值，float为例： 规格化，E各位不全为0也不全为1，即e!=0 &amp;&amp; e!=255。E = e - 127。所以E的范围其实是[-126, 127] 。此时 M = m + 1。所以最后绝对值为 M·2^E = (m+1)·2^(e-127)。 非规格化，全为0，e=0。E = 1 - 127. M = m。所以最后绝对值为 M·2^E = m·2^(-126)。 当m取最小值2^(-23) 时，这也是float能够表示的最小非零数，2^(-149)。 特殊值，全为1，e=255。当m=0时，根据符号位分别得到+∞和-∞。当m!=0时，得到NaN，意为 Not a Number。 至于为什么e=0时，M=m而不是M=m+1？ 此处结合e=0时，E也不是0-127，而是1-127,正好等于规格化的最小e，也是1-127。这个在非规格化向规格化过渡的时候，相同的指数值，保证整个f的值会随着m的增长而增大（线性的）。因此，对浮点数排序时，也可以像整数一样，直接比较其二进制位，从高位开始比较。 这个设计很有意思，假如在非规格化时，E=0-127，M=1+m，非规格化最大数为E=-127,M=1 + (2^23 -1)/2^23，f= 2^E ·M=2^(-126) -2^(-150) 。规格化最小数为E=1-127，M=1+0，f’=2^(-126) 。（哎？f’&gt;f，额这是哪里算错了吗？）f’-f=2^(-150). 真实情况是，非规格化最大数为E=1-127，M=(2^23 -1)/2^23，f= 2^(-126) -2^(-149) ，规格化最小数仍然是f’= 2^(-126)。 f’-f=2 ^ (-149)。这正是相邻的两个非规格化数的间隔2^(-126) ·2^(-23) =2^(-149)。也就是说IEEE的这种设计保持了在非规格化和规格化数之间的一个平滑过渡。 强转与舍入 int转为float，不会溢出，但是可能被舍入，毕竟都只有2^32个状态，能表达的总信息量是一定的。如 2^24 +1和2^24 强转为float后，值为2^24.000000。舍入的时候会有一种特殊情况，称为向偶数舍入，在非有效位值正好是两个可能值的中间值时，我们倾向于通过取舍，使得有效位的最后一位为0. double转float, 可能溢出为-∞或+∞. float和double转int，向零舍入。如果出现溢出，则值会变成0b1000 0000，也就是-Min。此处可以注意下。 浮点的运算主要是一点，不可结合，和分配，主要原因是，中间值可能会±∞或NaN。","categories":[{"name":"系统原理","slug":"系统原理","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"CSAPP","slug":"系统原理/CSAPP","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/CSAPP/"}],"tags":[{"name":"CSAPP","slug":"CSAPP","permalink":"http://yoursite.com/tags/CSAPP/"}]},{"title":"CSAPP-1-计算机系统漫游","slug":"CSAPP-1-计算机系统漫游","date":"2016-10-28T13:39:38.000Z","updated":"2016-10-28T13:39:38.000Z","comments":true,"path":"2016/10/28/CSAPP-1-计算机系统漫游/","link":"","permalink":"http://yoursite.com/2016/10/28/CSAPP-1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8/","excerpt":"","text":"写在前面工作找得差不多之后，总是感觉技术方向很迷茫。后面看一本书《暗时间》，上面说的对： 大量的新技术其实只是一层皮，背后的支撑技术其实都是十来年不变的东西。底层知识永不过时；算法数据结构永不过时；分析问题和解决问题的能力永不过时；强大的学习能力和旺盛的求知欲永不过时；你大脑的思维方式永不过时。 关于读书速度有选择地阅读。 对于一些逻辑混乱，作者都不知道自己问题是什么，或者上来就是技术方法细节，而不是从方法背后的理念出发，直观解释的书，没必要一定说服自己读下去，继续读反而是增加烦恼，浪费时间。 快or慢。 快慢从来不是一个问题，好书、知识密度大、需要思考的书就慢读。质量差，没啥的，该快就快，有必要过一遍的话，该不读就直接扔一边去，没必要纠结。“三天打鱼，两天晒网”的人往往最后会变成“整天晒网，永不打鱼”。也就是说耐心和恒心吧。一本再厚的书，每天看一点，总有看完的一天。 言归正传 信息就是 位+上下文 利用直接存储器存取（DMA）技术，数据可以不通过处理器而直接从磁盘到达内存。 hello world 程序在执行的时候，hello world 字符串复制路径：硬盘-&gt;主存-&gt;寄存器-&gt;显示设备。 一个典型系统的硬件组成： 存储设备形成设备层次 进程的上下文切换系统调用和中断的关系就在于，当进程发出系统调用申请的时候，会产生一个软件中断。产生这个软件中断以后，系统会去对这个软中断进行处理，这个时候进程就处于核心态了。 操作系统有两个基本的功能： 防止硬件被失控的应用程序滥用。（应用程序只能通过系统调用的方式来请求） 向应用程序提供简单一致的机制来控制复杂而又大相径庭的低级硬件设备。比如对于所有的I/O设备，包括硬盘、键盘、显示器、网络都视为文件，通过一组称为UNIX I/O的系统函数调用来实现输入输出。 操作系统内核是应用程序和硬件之间的媒介。提供三个基本的抽象： 文件是I/O设备的抽象 虚拟存储器是对主存和磁盘的抽象 进程是对一个正在运行的程序的抽象，包括处理器、主存和IO设备。","categories":[{"name":"系统原理","slug":"系统原理","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"CSAPP","slug":"系统原理/CSAPP","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/CSAPP/"}],"tags":[{"name":"CSAPP","slug":"CSAPP","permalink":"http://yoursite.com/tags/CSAPP/"}]},{"title":"java.io.FileNotFoundException-再次踩坑windows编码","slug":"java-io-FileNotFoundException-再次踩坑windows编码","date":"2016-03-24T08:26:10.000Z","updated":"2016-03-24T08:26:10.000Z","comments":true,"path":"2016/03/24/java-io-FileNotFoundException-再次踩坑windows编码/","link":"","permalink":"http://yoursite.com/2016/03/24/java-io-FileNotFoundException-%E5%86%8D%E6%AC%A1%E8%B8%A9%E5%9D%91windows%E7%BC%96%E7%A0%81/","excerpt":"","text":"####问题 为了方便读取文件，直接从windows文件属性里复制了路径，如图： 然后贴到eclipse里： 表面上看pathIn和pathIn2似乎没有什么不同，然而，在创建File对象时，总是提示java.io.FileNotFoundException，要报警，上次就碰到这个问题但是没解决。上次碰到的问题是，在windows一个问价夹里竟然可以存在两个同名文件！！####是时候展现真正的技术了我把那些字符串都复制出来，写一个简单的html来测试一下：看下实际效果：这下明了了，前面的”&amp;#8234 ;”特么是个什么鬼，CSDN markdown也打不出来这个字符串，分号和4之间没有空格。搜一下吧：从左到右的植入?关于双向文本https://en.wikipedia.org/wiki/Bi-directional_text推荐：http://www.iamcal.com/understanding-bidirectional-text/其实是unicode标准里，为了适配某些字符集的规定，比如阿拉伯语，显示的时候是从右向左的（为啥？难道他们写字是从右向左？果然是这样！！刚查了一下）后来我发现，windows里面其实有个小提示的，看箭头指的地方，有个浅灰色的竖线。然而复制到其他地方就不显示了，notepad里显示全部字符也不显示，但是确实被复制过去了。 这个问题网上的暂时还没见到这种解法，对于文件确实存在，但是总提示FileNotFound的，stackoverflow也都是让检查文件名是不是违反了windows的命名规则，希望这篇博文有所帮助。 刚开始简直有在电脑上装Ubuntu的冲动，然而想了想那么多的开发环境（手动再见）","categories":[],"tags":[]},{"title":"编码神坑之BOM","slug":"编码神坑之BOM","date":"2015-10-29T13:43:29.000Z","updated":"2015-10-29T13:43:29.000Z","comments":true,"path":"2015/10/29/编码神坑之BOM/","link":"","permalink":"http://yoursite.com/2015/10/29/%E7%BC%96%E7%A0%81%E7%A5%9E%E5%9D%91%E4%B9%8BBOM/","excerpt":"","text":"今天在做项目时，发现了一个超奇葩的问题。 背景条件： 客户端 java 后台php 问题： php后台使用”echo $result”返回了一个字符串“success”，但是这个字符串和java本地的”success”字符串用equals比较时竟然返回结果是false。 java端的代码： 过程： 哎哟喂，这个可把我给难住了，百思不得其解。直接打印返回的刚开始根据网上查到equals函数实现，自己写个函数替代equals，如下： 然后就单步跟踪调试了，发现281行的循环根本进不去，然后看了下变量各个字符的值，表面的问题终于找到了 这是返回字符串变量的各个位的字符。 这是本地用String succString = “success”生成的一个字符串。 可以发现，虽然第一行显示字符串的值都是“success”，然而，count和value一项都不一样。。 这简直醉了，难道是java网络数据读取的问题？（我为什么会怀疑到这个点。。） 继续找直接找到了post请求的返回数据，从里面一层一层也可以找到这个字符串的所在： 再继续展开value： 但是，为什么里面是这样子的，我还没想通，看起来也不像是因为字节序的问题，wireshark抓包结果 最后的7个数字确实跟success的ASCII码是一样的。 可以确认，之所以字符串前面有空白字符，是因为后台传返回数据即是这样。 为了查看后台返回的数据，我又写了个表单，用来直接模拟post请求： 输入数据，返回结果。表面没问题 审查元素： 可以看到，实际前面多了一串莫名其妙的字符 &amp;#65279 这一串数字可以直接google到，它其实是UTF-8编码的一个叫BOM的头。 BOM 全称 bom order mark，”EF BB BF” 这三个字节就叫BOM。 (这个为什么这么叫，似乎应该是固定好的标志，我试着用unicode解码并没有解出来”BOM“)。 在utf8文件中常用BOM来表明这个文件是UTF-8文件，而BOM的本意是在utf16中用。 utf-8文件在php中输出的时候bom是会被输出的，所以要在php中使用utf-8，必须要是使用不带bom头的utf-8文件。 wiki的解释非常不错，在里面也找到了各种编码的BOM标志。 https://zh.wikipedia.org/wiki/%E4%BD%8D%E5%85%83%E7%B5%84%E9%A0%86%E5%BA%8F%E8%A8%98%E8%99%9F 其次，windows的记事本保存的文本都是有BOM的，notepad++等文本编辑器可以设置无bom编码格式。 参考这个知乎问题：http://www.zhihu.com/question/20167122 嗯，修改编码格式后，一切正常。","categories":[],"tags":[]},{"title":"JAVA权限修饰符","slug":"JAVA权限修饰符","date":"2015-10-16T03:23:07.000Z","updated":"2015-10-16T03:23:07.000Z","comments":true,"path":"2015/10/16/JAVA权限修饰符/","link":"","permalink":"http://yoursite.com/2015/10/16/JAVA%E6%9D%83%E9%99%90%E4%BF%AE%E9%A5%B0%E7%AC%A6/","excerpt":"","text":"为了避免看了忘，忘了看，还是用文章记录下来吧。 应该说有四种权限修饰情况，public，protected，private，default public可以修饰类、成员变量、成员方法。几乎没有任何限制。 private可以修饰成员变量、成员方法、内部类。正好和public两个极端成员变量：本类内部访问，本类实例都不行。成员方法：同 成员变量内部类：同 成员变量 protected修饰成员变量、成员方法、内部类。成员变量：该变量可以在本类，本包内其他类，其他包的子类中访问成员方法：同 成员变量内部类：这个有点复杂，给个链接在这里吧：http://m.blog.csdn.net/blog/clarkdu/334925 default就是什么关键词都不写，修饰类、成员变量、成员方法default又称 包存取权限，对于default的类，只有同包中的类能够调用这个类的成员变量或方法。在类的修饰符与类成员修饰符相冲突时，比如类是default，而成员变量a为public，则实际上，a的存取权限也是default。 参考：http://blog.csdn.net/yan8024/article/details/6426451","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"C语言的字符0","slug":"C语言的字符0","date":"2014-12-02T08:34:30.000Z","updated":"2014-12-02T08:34:30.000Z","comments":true,"path":"2014/12/02/C语言的字符0/","link":"","permalink":"http://yoursite.com/2014/12/02/C%E8%AF%AD%E8%A8%80%E7%9A%84%E5%AD%97%E7%AC%A60/","excerpt":"","text":"首先对于字符，C语言里主要区分的依据是ascii编码表： 在计算机中，所有的数据在存储和运算时都要使用二进制数表示（因为计算机用高电平和低电平分别表示1和0），例如，像a、b、c、d这样的52个字母（包括大写）、以及0、1等数字还有一些常用的符号（例如*、#、@等）在计算机中存储时也要使用二进制数来表示，而具体用哪些二进制数字表示哪个符号，当然每个人都可以约定自己的一套（这就叫编码），而大家如果要想互相通信而不造成混乱，那么大家就必须使用相同的编码规则，于是美国有关的标准化组织就出台了ASCII编码，统一规定了上述常用符号用哪些二进制数来表示。以上百度百科ASCII http://baike.baidu.com/view/15482.htm需要明白的是，这里的映射关系式“字符” &lt;–&gt;”数字（编码）” 字符‘0’： 在这个表中，字符零，也就是C中的 ‘0’ 对应的是48，即，字符零在计算机中的存储是48。也就是说以下代码执行结果是48 123char czero &#x3D; &#39;0&#39;;printf(&quot;czero &#x3D; %d\\n&quot;, czero);执行结果： czero &#x3D; 48 数字0： 数字类型的数据在计算机中存储即是本身，就是0，看这段代码 12345678910int izero = 0;if (izero == czero)&#123; printf(\"czero = izero\\n\");&#125;else&#123; printf(\"czero != izero\\n\");&#125;执行结果: czero != izero 字符串“0”： 字符串“0”，很好理解，相当于存了两个符号，一个是字符‘0’，一个是字符串结尾标志‘\\0’，其实存储的十进制数就是数字0 字符串结尾标志‘\\0’： 虽然，大家都是这么说的，但其实，这里’\\0’，中的反斜线 \\ 可以当做转义符，其实就是转义符，跟 \\ 表示 \\，&#39; 表示 ‘ 一样，\\0 表示的就是 0，但是别忘记了这里的 \\0 是字符类型的，相当于裸0（我自己想的名字==），也就是数字0，数字0对应着哪个字符呢，查看下ASCII表格，发现第一个就是，NULL，这样也好理解了，在读取字符串的时候，末尾是NULL，但是必须有这个NULL，才能告诉编译器字符串结束了。 嗯，就是这样，另外多说一些：对于memset，memset(dst, 0, size) 和 memset(dst, ‘\\0’, size) 效果是一样的，但是和 memset(*dst, ‘0’, size) 不一样。 查看memset的定义：oid *memset(void *s, int ch, size_t n);函数解释：将s中前n个字节 （typedef unsigned int size_t ）用 ch 替换并返回 s 。memset：作用是在一段内存块中填充某个给定的值，它是对较大的结构体或数组进行清零操作的一种最快方法。 第二个本来就是数字啊，数字 0 和 字符’\\0’ 换成十进制数字都是0，但是字符’0’换算成数字是48，这也就可以理解了。要不做个试验: 123char szName[10];memset(szName,50, 10)printf(&quot;szName &#x3D; %s&quot;, szName); 这段代码的输出是，一串的222222222222222222222222222，不止10个一、输出2是因为，ASCII值50，对应的字符是2二、输出多余10个2，是因为我们把字符串结尾标志也memset掉了。嗯，虽然memset一般是用来初始化的，这时，直接用memset(*dst, 0, size)就行。","categories":[],"tags":[]}],"categories":[{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"系统原理","slug":"后端/系统原理","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"算法","slug":"后端/算法","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%AE%97%E6%B3%95/"},{"name":"安全","slug":"安全","permalink":"http://yoursite.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"},{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"方案总结","slug":"分布式/方案总结","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"},{"name":"系统原理","slug":"系统原理","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"},{"name":"CSAPP","slug":"系统原理/CSAPP","permalink":"http://yoursite.com/categories/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/CSAPP/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"算法思想","slug":"算法思想","permalink":"http://yoursite.com/tags/%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3/"},{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/%E5%AE%89%E5%85%A8/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"},{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"CSAPP","slug":"CSAPP","permalink":"http://yoursite.com/tags/CSAPP/"},{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]}