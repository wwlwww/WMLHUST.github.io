---
title: MySQL知识点
tags: [MySQL]
categories: [数据库,MySQL]
comments: true
date: 2020-05-20 11:09:35
updated: 2020-05-20 11:09:35
description: "总结一些mysql的知识点，包括范式、索引、事务、锁等等。"
---

## 范式与反范式
范式 | 描述 | 反例
--- | --- | ---
第一范式|每个字段都是原子的，不能再分解 | 某个字段是json串
第二范式|1. 表必须有主键；2. 非主属性，必须完全依赖主键，而不能只依赖主键的一部分字段。|如，好友关系表，关注人ID+被关注人ID作为主键，还存储了关注人的头像，这个只依赖于主键的一个字段。
第三范式|非主属性，直接依赖主键，而非间接依赖。| 如，员工表，有部门ID和部门名称等，部门名称依赖的是部门ID，而不是员工ID，不应在员工表中。

## 分库分表
比如电商订单表，有三个查询纬度：订单ID，用户ID，商户ID。
1. 建立主纬度和辅助纬度之间的一个映射表   
比如，以订单ID拆分，那么要保存`用户ID->订单ID`和`商户ID->订单ID`的映射表。然而问题是：
   1. 映射表本身也要分表
   2. 每个订单，要写入多个库，属于分布式事务问题。通常会由后台任务，定时对比，保证多库表最终一致。
2. 业务双写   
存多份数据，但是拆分纬度不一样。一套按用户ID划分，一套按商户号划分。同样存在写入多个库的分布式事务问题。
3. 异步双写   
还是多份数据，业务单写一份，然后通过监听binlog，同步到其他表上，这个方案整体更合适。
4. 多个纬度统一到一个纬度
比如把订单ID和用户ID统一成一个维度，然后把用户ID作为订单ID的一部分。这样，订单ID中就包含了用户ID的信息，然后按照用户ID分库，当按订单ID查询的时候，提取出用户ID，再按用户ID确定在那哪个库表中。   
**总之就是，拆分依据的维度，要同时在多个原始ID中体现**

## 分库分表后的Join问题
1. join拆分为多个单表查询，在应用层代码里做join处理
2. 增加宽表，提前join好
3. 利用搜索引擎，比如ES，将DB数据导入ES中

## 分布式事务
1. **最好是优化业务，避免跨库事务**
2. 如果无法避免，参考笔记：分布式事务一致性

## B+树
### 1. 优点
相比hash索引，以及类似结构的KV缓存或数据库，有以下特性
1. 范围查询
2. 前缀匹配，模糊查询
3. 排序和分页

### 2. 物理结构
1. 磁盘属于块设备，innoDB读写磁盘，是以page为基本单位，page默认大小是16KB，每次I/O都是16KB的整数倍。   
2. innoDB为每个Page赋予一个32位的全局编号，因此innoDB的存储上限是**64T** (2^32 * 16KB)。   
如果用来装非叶子节点，假如key是64位整数，也就是8字节，加上其他字段，按16字节算，一个page可以装1000个key。基于此估算，一个三层的B+树，可以存储的数据量：
    1. 第一层：根节点，一个page，1000个key。16KB内存，对应1000个子节点
    2. 第二层：1000个节点，每个节点一个page，每个page又可以有1000个子节点。16MB内存，对应1000 * 1000个子节点
    3. 第三层：1000 * 1000个节点，每个节点一个page。那么该表的最大容量是：1000 * 1000 * 16KB = 16GB。**只需要16MB的内存索引，只需要一次I/O读取叶子节点**    
3. 叶子page内部，以单向链表的方式，存储一条条的记录
4. 非主键索引，索引树叶子节点存的是主键的value。

## 事务与锁
### 1. 隔离级别
隔离级别|解决问题
---|---
Read Uncommited | 
Read commited | 解决脏读
Repeatable Read | 解决幻读（通过间隙锁），innoDB默认级别。MVCC需要结合行锁，实现当前读，解决update时的覆盖问题。
Serialization | 

### 2. 死锁检测
1. 判断一个有向图是否存在环，dfs、拓扑排序
2. 死锁的发生，与代码有关，也与事务隔离级别有关，因为隔离级别会影响加锁机制。
3. 复杂度是O(N)

### 3. innoDB的MVCC实现
1. 每一行都有两个隐藏列，**最近修改的事务ID** + **undolog里回滚段指针（便于回滚）**
2. 一致性视图，{low_trx_id, up_trx_id, trx_ids}   
    - low_trx_id: 当前事务链表，最小的事务id
    - up_trx_id:  当前事务链表，最大的事务id
    - trx_ids: 正在执行的事务的id集合   
    
    **通过比较当前事务id，与以上三个变量的关系，确定某个版本数据，是否对当前事务可见。**

### 4. 事务实现
#### 1. WAL, Write-Ahead Log
内存操作数据 + write-ahead log，提高写入速度

#### 2. Redo Log的逻辑与物理结构
1. redo log 物理组成结构
    1. 一个逻辑事务 包含 多个物理事务mtr，Mini Transaction
    2. 每个mtr对应一个LSN
    3. 一个LSN对应若干个**连续的block**，所以每个mtr在redo log里是连续存储的，而整个事务的redo log不一定连续。
    4. 这些block，最终组成了 redo log   

    **综上，一个事务在redo log里，可能有多个LSN，这些LSN自己是连续的，但是多个LSN不一定是连续的。**

2. redo log 日志内容格式
    1. 先以page为单位记录日志
    2. 在每个page里面再采用物理记法，比如 (page_id, record_offset, (field1, value1)..(fieldi, valuei)...)   

3. Aries恢复算法
    1. 分析阶段   
    从上一个checkpoint开始，开始分析哪些事务执行完了，未刷写page；哪些事务执行了一半，需要回滚。checkpoint机制，可以加快分析速度
    2. redo阶段
    对已经commit的事务，执行redolog，刷写page。redolog是幂等的，重复执行没关系。
    3. undo阶段   
    对于未commit的事务，执行undolog，回滚
4. 其他
    1. 每个page上记录了，上次修改的LSN，因此恢复时，如果redolog里的 lsn < page lsn，说明不用重写了。
    2. redolog保证的是事务的持久性，写入成功，则不会丢失

#### 3. Undo log
1. redolog按LSN的顺序，而undolog没有顺序，多个事务并行写。每条日志除下记录主键ID和数据外，还有两个字段：修改记录的事务ID和回滚指针，用来串联所有历史版本，就是MVCC的两个隐藏列。
2. undo log 只在commit的过程中有用，一旦事务commit了，就可以删掉undo log
3. 通俗一点，修改行前，先把行拷贝一份出来，这些历史版本形成一个链表。
    
## 各种锁
1. 有不同的划分标准，比如按粒度，有`表锁`、`行锁`、`gap锁`；按锁的模式，有`共享锁`、`排他锁`、`意向锁`等
2. MySQL加锁问题与隔离级别有关，比如：Read Commited 级别不需要gap锁，因为RC允许幻读。
2. 具体到各种锁
    1. `全局锁`：对整个DB加锁，一些不支持事务的引擎，可以在备份前，锁住DB，避免备份时，一个读一个写，数据发生变化，造成数据不一致。
    2. `MDL`，元数据锁：MDL分读/写，不需显式调用。MDL也是在语句执行时隐式加，在事务提交后释放。比如在对表做CURD时，加MDL读锁；对表做DDL时，加MDL写锁。
    3. `表锁`，读锁/写锁，共享/排他，S/X，不赘述。
    4. `行锁`，读锁/写锁，共享/排他，S/X
    4. `意向锁`，意向锁也是表级别，但是意向锁之间互不排斥，包括IX（意向写）与IX也不互斥。**意向锁的目的是提高在加表锁时的判断效率。** 如果事务要给表中某一行加X锁，首先要对表加IX锁；如果要给某一行加S锁，就先对表加IS锁。这也是“意向”一词的含义。   
    如果一个事务要对表加X锁，就可以根据表有没有被其他事务加IS/IX锁，就可得知，有没有其他事务在读写该表。
    5. `间隙锁`，解决幻读问题
    6. `AI锁`，表级别，针对自增ID生成器，如果事务rollback，自增ID一列会不连续

## 其他问题

1. double write 机制   

    InnoDB的page size一般是16KB，其数据校验也是针对这16KB来计算的，将数据写入到磁盘是以page为单位进行操作的。操作系统写文件是以4KB作为单位的，磁盘IO是以512字节为单位的，那么每写一个InnoDB的page到磁盘上，操作系统需要写4个块。**而计算机硬件和操作系统，在极端情况下（比如断电）往往并不能保证这一操作的原子性。**   
    如果16K的数据，写入4K时，发生了系统断电或系统崩溃，只有一部分写是成功的，这种情况下就是partial page write（部分页写入）问题。这时page数据出现不一样的情形，从而形成一个"断裂"的page，使数据产生混乱。这个时候InnoDB对这种块错误是无能为力的.   

    有人会认为系统恢复后，MySQL可以根据redo log进行恢复，而MySQL在恢复的过程中是检查page的checksum，如果会发现该page已经损坏，就无法确定上次修改page的事务id，因而在重放redolog时无法顺利恢复，即使重放了整个redo log，也无法严谨地证明数据完全恢复了。

    为了解决该问题，写数据page时，写两遍到磁盘，第一遍是写到double write buffer文件上, 第二遍是从double write buffer写到真正的数据文件中。如果宕机重启，发现page损坏，可以从double write buffer中恢复。   

    因为redo log的写入单位就是512字节，也就是磁盘IO的最小单位，因此可以保证原子性，不会导致数据损坏。

## 参考
1. [索引工作原理](https://github.com/0voice/interview_internal_reference/blob/master/09.MySQL%E7%AF%87/9.1.4%20%E7%B4%A2%E5%BC%95%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E7%A7%8D%E7%B1%BB.md)












